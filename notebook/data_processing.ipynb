{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "# generic\n",
    "import os\n",
    "import sys    \n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# custom\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-existing spacy model\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "# Getting the pipeline component\n",
    "ner=nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../traindata_edited.json\"\n",
    "test_dir = \"../testdata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "lines = []\n",
    "\n",
    "with open(train_dir, \"rb\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    data = json.loads(line)\n",
    "    text = data[\"content\"]\n",
    "    entities = []\n",
    "    for annotation in data[\"annotation\"]:\n",
    "        # only a single point in text annotation.\n",
    "        point = annotation[\"points\"][0]\n",
    "        labels = annotation[\"label\"]\n",
    "        # handle both list of labels or a single label.\n",
    "        if not isinstance(labels, list):\n",
    "            labels = [labels]\n",
    "\n",
    "        for label in labels:\n",
    "            # dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
    "            entities.append((point[\"start\"], point[\"end\"] + 1, label))\n",
    "\n",
    "    training_data.append((text, {\"entities\": entities}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/explosion/spaCy/issues/3558\n",
    "import re\n",
    "\n",
    "\n",
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = trim_entity_spans(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels to the `ner`\n",
    "\n",
    "for _, annotations in training_data:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pipeline components you dont need to change\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Puneeth R\n",
      "Escalation Specialist - HiPower Support ...\" with entities \"[[2182, 2210, 'College Name'], [2177, 2180, 'Degre...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Madhava Konjeti\n",
      "HR Executive\n",
      "\n",
      "Bengaluru, Karnataka...\" with entities \"[[1818, 1892, 'Skills'], [1761, 1765, 'Graduation ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Urshila Lohani\n",
      "Senior Corporate Account Executive ...\" with entities \"[[2635, 2639, 'Graduation Year'], [2568, 2590, 'Co...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Jacob Philip\n",
      "Kottayam, Kerala - Email me on Indeed...\" with entities \"[[2165, 2214, 'Skills'], [2145, 2155, 'Degree'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 456.84234046936035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Arpit Jain\n",
      "Quality Analyst - ThoughtWorks Technolo...\" with entities \"[[2301, 2380, 'Skills'], [2088, 2131, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"amarjyot sodhi\n",
      "Voice and Accent Trainer :Masters i...\" with entities \"[[1130, 1174, 'Email Address'], [1112, 1116, 'Grad...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Imgeeyaul Ansari\n",
      "java developer\n",
      "\n",
      "Pune, Maharashtra...\" with entities \"[[1894, 2173, 'Skills'], [1726, 1850, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 1153.6221137046814}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Tejasri Gunnam\n",
      "Bengaluru, Karnataka - Email me on ...\" with entities \"[[3517, 3878, 'Skills'], [3387, 3481, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Abdul B\n",
      "Arabic Language supporter (Content Analyst...\" with entities \"[[2349, 2471, 'Skills'], [2331, 2340, 'Degree'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 2095.128128528595}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Suresh Kanagala\n",
      "Architecture SharePoint/Office 365...\" with entities \"[[1171, 1573, 'Skills'], [962, 1095, 'Skills'], [9...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Roshan Sinha\n",
      "Application Developer - SAP ABAP\n",
      "\n",
      "Kol...\" with entities \"[[3255, 3264, 'Skills'], [3246, 3254, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 2371.3693981319666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Laya A\n",
      "Cluster HR Manager - Velammal New\n",
      "\n",
      "Chennai,...\" with entities \"[[3760, 4638, 'Skills'], [3727, 3742, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Srinivas VO\n",
      "Sr. Test Manager\n",
      "\n",
      "Mumbai, Maharashtra ...\" with entities \"[[11201, 11408, 'Skills'], [11172, 11191, 'College...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3242.9847793728113}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Senthil Kumar\n",
      "Senior Technical Lead - HCL Cisco\n",
      "\n",
      "-...\" with entities \"[[6646, 7279, 'Skills'], [6451, 6554, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sameer Kujur\n",
      "Orrisha - Email me on Indeed: indeed....\" with entities \"[[265, 307, 'Email Address'], [210, 251, 'Skills']...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Nidhi Pandit\n",
      "Test Engineer - Infosys Limited\n",
      "\n",
      "- Em...\" with entities \"[[3132, 3611, 'Skills'], [3005, 3082, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3920.31965829432}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Rupesh Reddy\n",
      "Technology Consultant - EIT Services ...\" with entities \"[[6732, 6848, 'Skills'], [6703, 6705, 'Graduation ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Raktim Podder\n",
      "6+ Exp in banking operations and cre...\" with entities \"[[8800, 8927, 'Skills'], [8760, 8788, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Zaheer Uddin\n",
      "Technical Project Manager\n",
      "\n",
      "Hyderabad,...\" with entities \"[[4901, 4909, 'Location'], [4843, 4861, 'College N...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 4315.14881016314}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Suman Biswas\n",
      "SAP UI5 Lead, Native HANA Developer -...\" with entities \"[[5053, 5058, 'Companies worked at'], [5013, 5018,...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 4841.294818177819}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ravi Shivgond\n",
      "Bidar, Karnataka - Email me on Indee...\" with entities \"[[1341, 1384, 'Email Address'], [1131, 1136, 'Loca...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 5376.564513459802}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Pankaj Bhosale\n",
      "Microsoft SQL-SERVER\n",
      "\n",
      "Dhule, Mahara...\" with entities \"[[1482, 1487, 'Location'], [1369, 1413, 'Email Add...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Saurabh Sandhikar\n",
      "SAURABH SANDHIKAR\n",
      "\n",
      "Hyderabad, Te...\" with entities \"[[2562, 2597, 'Skills'], [2366, 2375, 'Companies w...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 6688.892485871911}\n",
      "Losses {'ner': 7564.701426759362}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Koushik Katta\n",
      "Devops\n",
      "\n",
      "Hyderabad, Telangana - Email...\" with entities \"[[2957, 3073, 'Skills'], [2943, 2947, 'Graduation ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Mahesh Vijay\n",
      "Bengaluru, Karnataka - Email me on In...\" with entities \"[[3823, 3978, 'Skills'], [3466, 3819, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"B. Gokul\n",
      "Gokul, Uttar Pradesh - Email me on Indeed...\" with entities \"[[970, 1002, 'Skills'], [863, 868, 'Location'], [6...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 8108.563119187951}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Chhaya Prabhale\n",
      "Kharadi, Pune, 411014, IN - Email ...\" with entities \"[[1943, 2050, 'Skills'], [478, 488, 'Designation']...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Shreyanshu Gupta\n",
      "Software Development Engineer wit...\" with entities \"[[4167, 4170, 'Skills'], [4141, 4145, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ram Edupuganti\n",
      "Software Development Director - Ora...\" with entities \"[[4960, 4964, 'Graduation Year'], [4938, 4958, 'Co...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 8475.717280998826}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Soumya Balan\n",
      "IT SUPPORT\n",
      "\n",
      "Sulthan Bathery, Kerala, ...\" with entities \"[[3913, 4370, 'Skills'], [3884, 3880, 'Graduation ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ramesh HP\n",
      "CES ASSOCIATE CONSULTANT\n",
      "\n",
      "Bangalore, Kar...\" with entities \"[[2669, 2944, 'Skills'], [2618, 2638, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 8674.262307852507}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Siddhartha Chetri\n",
      "7 years of experience in IT Netw...\" with entities \"[[5471, 5838, 'Skills'], [5457, 5461, 'Graduation ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 9152.562431305647}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Nida Khan\n",
      "Tech Support Executive - Teleperformance...\" with entities \"[[872, 911, 'Email Address'], [800, 858, 'Skills']...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Palani S\n",
      "Senior Technology Support Executive at In...\" with entities \"[[3660, 3663, 'Graduation Year'], [3600, 3602, 'Gr...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 9404.407358974218}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Mayank Shukla\n",
      "Infosys group as a Test Analyst - In...\" with entities \"[[2348, 3131, 'Skills'], [2324, 2328, 'Graduation ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Mohini Gupta\n",
      "Server Support Engineer\n",
      "\n",
      "Gurgaon, Har...\" with entities \"[[2326, 2333, 'Location'], [1821, 2095, 'Skills'],...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 9955.960100024939}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ravi Shankar\n",
      "Working as Escalation Engineer with M...\" with entities \"[[4016, 4025, 'Companies worked at'], [3941, 3950,...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ramya. P\n",
      "Hyderabad, Telangana - Email me on Indeed...\" with entities \"[[4542, 4549, 'Skills'], [4178, 4187, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 10712.683423370123}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Arpit Godha\n",
      "Senior Process Executive\n",
      "\n",
      "Jaipur, Raja...\" with entities \"[[3144, 3495, 'Skills'], [3081, 3104, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Karthik Gururaj\n",
      "Technical Lead at Infosys Ltd. - P...\" with entities \"[[2814, 2839, 'Degree'], [2773, 2812, 'Degree'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Divesh Singh\n",
      "Bengaluru, Karnataka - Email me on In...\" with entities \"[[948, 1180, 'Skills'], [833, 845, 'College Name']...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 10935.160366863012}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Karthik G V\n",
      "Program Manager, Product Manager, Prod...\" with entities \"[[1750, 1759, 'Companies worked at'], [1467, 1476,...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Nitin Tr\n",
      "PeopleSoft Consultant\n",
      "\n",
      "Bangalore Urban, K...\" with entities \"[[3511, 3749, 'Skills'], [3313, 3364, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 11322.10897526145}\n",
      "Losses {'ner': 11564.82072646916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ganesh AlalaSundaram\n",
      "A Dev-Test Professional with ...\" with entities \"[[3321, 3376, 'Skills'], [3296, 3311, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sohan Dhakad\n",
      "Shivpuri, Madhya Pradesh - Email me o...\" with entities \"[[870, 893, 'Skills'], [794, 810, 'College Name'],...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Pratibha P\n",
      "Principal Consultant at Oracle\n",
      "\n",
      "Bengalu...\" with entities \"[[3345, 3896, 'Skills'], [3276, 3313, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 11846.12884195149}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Pradeeba V\n",
      "LEAD ENGINEER - CISCO\n",
      "\n",
      "- Email me on In...\" with entities \"[[2707, 2711, 'Skills'], [2683, 2693, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 12341.834150865674}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Jatin Arora\n",
      "SDET Automation Engineer, Infosys - CR...\" with entities \"[[3909, 3931, 'College Name'], [3883, 3907, 'Degre...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Shaik Tazuddin\n",
      "Senior Process Executive - STAR Ind...\" with entities \"[[2877, 3031, 'Skills'], [2728, 2742, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 12516.828362300992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"VARUN AHLUWALIA\n",
      "Quantitative Analyst\n",
      "\n",
      "- Email me o...\" with entities \"[[773, 847, 'Skills'], [736, 740, 'Graduation Year...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sanand Pal\n",
      "SQL and MSBI Developer with experience ...\" with entities \"[[3056, 3090, 'Skills'], [3042, 3046, 'Graduation ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 12830.611467197537}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Navas Koya\n",
      "Test Engineer\n",
      "\n",
      "Mangalore, Karnataka - E...\" with entities \"[[2110, 2404, 'Skills'], [2055, 2064, 'Location'],...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Debasish Dasgupta\n",
      "Trainer-Finacle-Core Banking Sol...\" with entities \"[[5840, 5847, 'Companies worked at'], [2090, 2137,...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Jaspreet Kaur\n",
      "Oceanic Consultants as a HR Executiv...\" with entities \"[[5670, 5780, 'Skills'], [462, 481, 'Designation']...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 13114.72632856667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Asha Subbaiah\n",
      "(Microsoft Partner Readiness Operati...\" with entities \"[[3345, 3380, 'College Name'], [3322, 3343, 'Degre...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Mohammed Murtuza\n",
      "Major Incident Manager / Escalati...\" with entities \"[[7924, 8039, 'Skills'], [7872, 7891, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 13608.832463935018}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Chaban kumar Debbarma\n",
      "Tripura - Email me on Indeed...\" with entities \"[[277, 328, 'Email Address'], [257, 263, 'College ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 13931.022941544652}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Fenil Francis\n",
      "head of operation and logistics\n",
      "\n",
      "Tri...\" with entities \"[[774, 897, 'Skills'], [694, 728, 'Skills'], [648,...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Hartej Kathuria\n",
      "Data Analyst Intern - Oracle Retai...\" with entities \"[[2247, 2573, 'Skills'], [1435, 1480, 'Email Addre...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 14260.432606652379}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sharan Adla\n",
      "- Email me on Indeed: indeed.com/r/Sha...\" with entities \"[[2421, 2450, 'College Name'], [2416, 2419, 'Degre...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Aarti Pimplay\n",
      "Operations Center Shift Manager (OCS...\" with entities \"[[3054, 3363, 'Skills'], [2333, 2339, 'Companies w...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Kavitha K\n",
      "Senior System Engineer - Infosys Limited...\" with entities \"[[2292, 2296, 'Graduation Year'], [2245, 2269, 'Co...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Puran Mal\n",
      "Jaipur, Rajasthan - Email me on Indeed: ...\" with entities \"[[194, 511, 'Skills'], [174, 183, 'Degree'], [127,...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 14454.490203772672}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Akansha Jain\n",
      "Pune, Maharashtra - Email me on Indee...\" with entities \"[[1860, 1871, 'Name'], [1502, 1600, 'Skills'], [12...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Paul Rajiv\n",
      "Secunderabad, Andhra Pradesh - Email me...\" with entities \"[[4729, 4733, 'Graduation Year'], [2634, 2638, 'Gr...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Gunjan Nayyar\n",
      "Hoshiarpur, Punjab - Email me on Ind...\" with entities \"[[1234, 1277, 'Email Address'], [1146, 1150, 'Grad...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 14546.133324743249}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Soumya Balan\n",
      "IT SUPPORT\n",
      "\n",
      "Sulthan Bathery, Kerala, ...\" with entities \"[[4167, 4176, 'Companies worked at'], [3913, 4040,...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Puneet Singh\n",
      "Associate Software Engineer\n",
      "\n",
      "Bengalur...\" with entities \"[[990, 1007, 'Skills'], [952, 968, 'Skills'], [919...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Pawan Nag\n",
      "Microsoft Certified System Engineer\n",
      "\n",
      "Del...\" with entities \"[[523, 562, 'Email Address'], [500, 509, 'Name'], ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 14893.111695648171}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Angad Waghmare\n",
      "Pune, Maharashtra - Email me on Ind...\" with entities \"[[3878, 3937, 'Degree'], [3111, 3846, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 15011.112698980607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Akshay Dubey\n",
      "Actively looking for opportunity in ....\" with entities \"[[2889, 3087, 'Skills'], [2734, 2846, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sudaya Puranik\n",
      "Principal Engineer Technical Staff ...\" with entities \"[[2656, 2688, 'Skills'], [2586, 2626, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 15307.647357412614}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Vishwanath P\n",
      "Senior Executive (MIS & Audit) - Job ...\" with entities \"[[8139, 8163, 'College Name'], [8134, 8136, 'Degre...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Srushti Bhadale\n",
      "Mumbai, Maharashtra - Email me on ...\" with entities \"[[1551, 1852, 'Skills'], [1454, 1499, 'Email Addre...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Keshav Dhawale\n",
      "3 TCS Security guard Access Control...\" with entities \"[[971, 1015, 'Email Address'], [877, 895, 'College...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 15615.263697334565}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Kandrapu Reddy\n",
      "Senior Travel Operations (Domestic,...\" with entities \"[[4232, 4330, 'Skills'], [4058, 4101, 'Degree'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Dilliraja Baskaran\n",
      "Tamil Nadu - Email me on Indeed...\" with entities \"[[363, 411, 'Email Address'], [314, 349, 'Skills']...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 15916.22224802617}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Vineeth Vijayan\n",
      "\"Store Executive\" - Orange City Ho...\" with entities \"[[6994, 7350, 'Skills'], [6936, 6973, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Vinay Singhal\n",
      "New Delhi, Delhi - Email me on Indee...\" with entities \"[[937, 980, 'Email Address'], [580, 923, 'Skills']...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 16450.696176477708}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Pavithra M\n",
      "\"Infosys\" internship\n",
      "\n",
      "Bengaluru, Karnat...\" with entities \"[[998, 1038, 'Email Address'], [611, 984, 'Skills'...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 16819.80001587514}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Anurag Asthana\n",
      "Pune, Maharashtra - Email me on Ind...\" with entities \"[[7675, 7692, 'Years of Experience'], [7133, 7595,...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Nitin Verma\n",
      "Assisting Microsoft Partners - Exchang...\" with entities \"[[1308, 1349, 'Email Address'], [1277, 1281, 'Loca...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 17172.308536955155}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Priyesh Dubey\n",
      "Azure Developer with 9 Yrs 8 months ...\" with entities \"[[2547, 2756, 'Skills'], [2537, 2546, 'Companies w...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 17542.753467031755}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Kavya U.\n",
      "Network Ops Associate - Accenture\n",
      "\n",
      "Bengal...\" with entities \"[[1844, 1873, 'Skills'], [1794, 1830, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Shraddha Achar\n",
      "Mathura, Uttar Pradesh - Email me o...\" with entities \"[[975, 1020, 'Skills'], [814, 843, 'College Name']...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 17882.734192320146}\n",
      "Losses {'ner': 18076.531017609872}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Praveen Bhaskar\n",
      "Program Manager (Software Delivery...\" with entities \"[[4459, 4959, 'Skills'], [4445, 4450, 'Designation...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 18270.408949800767}\n",
      "Losses {'ner': 18533.5707182372}\n",
      "Losses {'ner': 18896.89236111287}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Krishna Prasad\n",
      "Patna, Bihar - Email me on Indeed: ...\" with entities \"[[283, 327, 'Email Address'], [257, 262, 'Location...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Yogesh Ghatole\n",
      "Engineer / Electrical Supervisor, S...\" with entities \"[[2912, 3288, 'Skills'], [2721, 2726, 'UNKNOWN'], ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ajay Elango\n",
      "Software Engineer\n",
      "\n",
      "Bangalore City, Kar...\" with entities \"[[6930, 7494, 'Skills'], [6845, 6874, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 19357.450734087266}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sai Dhir\n",
      "- Email me on Indeed: indeed.com/r/Sai-Dh...\" with entities \"[[2956, 3016, 'Skills'], [2567, 2952, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Jyotirbindu Patnaik\n",
      "Associate consultant@SAP labs ...\" with entities \"[[3052, 3067, 'Skills'], [2993, 3016, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Rajeev Kumar\n",
      "Senior Associate Consultant - Infosys...\" with entities \"[[3982, 4412, 'Skills'], [3162, 3674, 'Skills'], [...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 19878.24602789525}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Avani Priya\n",
      "- Email me on Indeed: indeed.com/r/Ava...\" with entities \"[[368, 409, 'Email Address'], [314, 334, 'College ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ashish Indoriya\n",
      "Sr. Systems Engineer at Infosys Li...\" with entities \"[[3828, 3931, 'Skills'], [3753, 3794, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sridevi H\n",
      "Bangalore, Karnataka - Email me on Indee...\" with entities \"[[2473, 2498, 'Designation'], [2030, 2037, 'Compan...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\febri\\anaconda3\\envs\\parsecv\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Madhuri Sripathi\n",
      "Banglore, Karnataka, Karnataka - ...\" with entities \"[[4563, 4746, 'Skills'], [4538, 4551, 'College Nam...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 20462.06021256093}\n",
      "Losses {'ner': 20513.49948931951}\n",
      "Losses {'ner': 279.7355834245682}\n",
      "Losses {'ner': 699.4176083803177}\n",
      "Losses {'ner': 1094.9760357141495}\n",
      "Losses {'ner': 1575.5158644914627}\n",
      "Losses {'ner': 2016.8031123876572}\n",
      "Losses {'ner': 2398.37982070446}\n",
      "Losses {'ner': 2653.4381049871445}\n",
      "Losses {'ner': 3011.599970936775}\n",
      "Losses {'ner': 3379.6184417009354}\n",
      "Losses {'ner': 3668.4030777215958}\n",
      "Losses {'ner': 4118.679510951042}\n",
      "Losses {'ner': 4378.796913027763}\n",
      "Losses {'ner': 4522.77527564764}\n",
      "Losses {'ner': 4618.606311999261}\n",
      "Losses {'ner': 5023.214799128473}\n",
      "Losses {'ner': 5131.871185772121}\n",
      "Losses {'ner': 5354.804783336818}\n",
      "Losses {'ner': 5461.498540110886}\n",
      "Losses {'ner': 5656.581805296242}\n",
      "Losses {'ner': 5813.544078834355}\n",
      "Losses {'ner': 5993.234286375344}\n",
      "Losses {'ner': 6485.795117922127}\n",
      "Losses {'ner': 6824.060422964394}\n",
      "Losses {'ner': 7023.1359016522765}\n",
      "Losses {'ner': 7329.298180781305}\n",
      "Losses {'ner': 7631.995694838464}\n",
      "Losses {'ner': 7832.428013049066}\n",
      "Losses {'ner': 8095.90199624747}\n",
      "Losses {'ner': 8723.119214169681}\n",
      "Losses {'ner': 8834.829456351697}\n",
      "Losses {'ner': 8953.069510482252}\n",
      "Losses {'ner': 9198.408857367933}\n",
      "Losses {'ner': 9576.012009643018}\n",
      "Losses {'ner': 9942.040416263044}\n",
      "Losses {'ner': 10246.713356755674}\n",
      "Losses {'ner': 10479.989941440523}\n",
      "Losses {'ner': 10752.417407356203}\n",
      "Losses {'ner': 10937.015159033239}\n",
      "Losses {'ner': 11683.5709470734}\n",
      "Losses {'ner': 11962.360417030752}\n",
      "Losses {'ner': 12145.57395567745}\n",
      "Losses {'ner': 12441.991995118558}\n",
      "Losses {'ner': 12633.38793488592}\n",
      "Losses {'ner': 12713.527587354183}\n",
      "Losses {'ner': 13849.83725875616}\n",
      "Losses {'ner': 14229.26829379797}\n",
      "Losses {'ner': 14495.919988572598}\n",
      "Losses {'ner': 15038.926938951015}\n",
      "Losses {'ner': 15268.525182187557}\n",
      "Losses {'ner': 298.90262722969055}\n",
      "Losses {'ner': 574.4479331970215}\n",
      "Losses {'ner': 887.1473660469055}\n",
      "Losses {'ner': 979.0777264609933}\n",
      "Losses {'ner': 1471.7201567664742}\n",
      "Losses {'ner': 1648.8114094510674}\n",
      "Losses {'ner': 2046.8835572972894}\n",
      "Losses {'ner': 2163.8281116895378}\n",
      "Losses {'ner': 2429.3599102906883}\n",
      "Losses {'ner': 2564.80436110124}\n",
      "Losses {'ner': 2599.9700927883387}\n",
      "Losses {'ner': 2964.192722812295}\n",
      "Losses {'ner': 3180.757328674197}\n",
      "Losses {'ner': 3307.28464857582}\n",
      "Losses {'ner': 3617.3591014528647}\n",
      "Losses {'ner': 4462.6464301729575}\n",
      "Losses {'ner': 4634.3652744675055}\n",
      "Losses {'ner': 4735.123828109121}\n",
      "Losses {'ner': 4986.01278870902}\n",
      "Losses {'ner': 5061.689157517394}\n",
      "Losses {'ner': 5444.026416809997}\n",
      "Losses {'ner': 5751.301040442428}\n",
      "Losses {'ner': 6070.422515662154}\n",
      "Losses {'ner': 6394.355939896544}\n",
      "Losses {'ner': 6923.180825264892}\n",
      "Losses {'ner': 7060.604600788793}\n",
      "Losses {'ner': 7392.133222939214}\n",
      "Losses {'ner': 7685.89978313609}\n",
      "Losses {'ner': 7930.12496805354}\n",
      "Losses {'ner': 8619.940316678723}\n",
      "Losses {'ner': 9301.040375234326}\n",
      "Losses {'ner': 9504.872867466649}\n",
      "Losses {'ner': 9646.58776486083}\n",
      "Losses {'ner': 10060.151757599553}\n",
      "Losses {'ner': 10285.918984057149}\n",
      "Losses {'ner': 10470.47659188672}\n",
      "Losses {'ner': 10743.218915762147}\n",
      "Losses {'ner': 11199.054643930634}\n",
      "Losses {'ner': 11692.25594741269}\n",
      "Losses {'ner': 11926.715868295869}\n",
      "Losses {'ner': 12178.254231752595}\n",
      "Losses {'ner': 12393.272601904115}\n",
      "Losses {'ner': 12540.972998531302}\n",
      "Losses {'ner': 12677.588838727912}\n",
      "Losses {'ner': 12919.84305063053}\n",
      "Losses {'ner': 13054.813128379872}\n",
      "Losses {'ner': 13267.476677385857}\n",
      "Losses {'ner': 13395.778132304316}\n",
      "Losses {'ner': 13500.09019026137}\n",
      "Losses {'ner': 104.89470233023167}\n",
      "Losses {'ner': 258.17763878405094}\n",
      "Losses {'ner': 519.3175904899836}\n",
      "Losses {'ner': 685.8679380565882}\n",
      "Losses {'ner': 817.0740234702826}\n",
      "Losses {'ner': 948.8617467135191}\n",
      "Losses {'ner': 1274.3640459030867}\n",
      "Losses {'ner': 1444.7937738373876}\n",
      "Losses {'ner': 1592.7014140412211}\n",
      "Losses {'ner': 1929.7005121037364}\n",
      "Losses {'ner': 2161.593587331474}\n",
      "Losses {'ner': 2548.4161211773753}\n",
      "Losses {'ner': 2848.5708882138133}\n",
      "Losses {'ner': 2970.2053121849895}\n",
      "Losses {'ner': 3203.7032100483775}\n",
      "Losses {'ner': 3288.0985502302647}\n",
      "Losses {'ner': 3437.0483678281307}\n",
      "Losses {'ner': 3662.659590393305}\n",
      "Losses {'ner': 3839.253882139921}\n",
      "Losses {'ner': 4026.8945682942867}\n",
      "Losses {'ner': 4615.4229753911495}\n",
      "Losses {'ner': 4822.975927680731}\n",
      "Losses {'ner': 5014.786710232496}\n",
      "Losses {'ner': 5100.181236198172}\n",
      "Losses {'ner': 6082.0007695462555}\n",
      "Losses {'ner': 6271.001895954832}\n",
      "Losses {'ner': 6461.2809221651405}\n",
      "Losses {'ner': 6639.126882901415}\n",
      "Losses {'ner': 6922.719037881121}\n",
      "Losses {'ner': 7039.494467904791}\n",
      "Losses {'ner': 7157.304016819224}\n",
      "Losses {'ner': 7485.118603756651}\n",
      "Losses {'ner': 7608.555651305243}\n",
      "Losses {'ner': 7790.106837866828}\n",
      "Losses {'ner': 8098.558460114524}\n",
      "Losses {'ner': 8299.017064927146}\n",
      "Losses {'ner': 8469.948490468785}\n",
      "Losses {'ner': 8772.878478853032}\n",
      "Losses {'ner': 9014.771281091496}\n",
      "Losses {'ner': 9166.846464244649}\n",
      "Losses {'ner': 9286.479231772013}\n",
      "Losses {'ner': 9401.788478312083}\n",
      "Losses {'ner': 10029.567914423533}\n",
      "Losses {'ner': 10228.859657076187}\n",
      "Losses {'ner': 10372.05508124549}\n",
      "Losses {'ner': 10480.987458285876}\n",
      "Losses {'ner': 10740.769747850485}\n",
      "Losses {'ner': 10831.232738711871}\n",
      "Losses {'ner': 10918.413211219944}\n",
      "Losses {'ner': 233.0357084274292}\n",
      "Losses {'ner': 340.4007238280028}\n",
      "Losses {'ner': 509.69182230345905}\n",
      "Losses {'ner': 670.9752436112612}\n",
      "Losses {'ner': 878.5200852584094}\n",
      "Losses {'ner': 1121.6109505724162}\n",
      "Losses {'ner': 1389.1115151476115}\n",
      "Losses {'ner': 1662.1411875318736}\n",
      "Losses {'ner': 1860.21213994734}\n",
      "Losses {'ner': 1964.617988763377}\n",
      "Losses {'ner': 2223.8389347773045}\n",
      "Losses {'ner': 2387.7949614506215}\n",
      "Losses {'ner': 2513.7803589683026}\n",
      "Losses {'ner': 2970.686010060832}\n",
      "Losses {'ner': 3094.400187222287}\n",
      "Losses {'ner': 3329.678006378934}\n",
      "Losses {'ner': 3424.040593229234}\n",
      "Losses {'ner': 3657.1720970496535}\n",
      "Losses {'ner': 3721.038205341436}\n",
      "Losses {'ner': 3822.5412294426933}\n",
      "Losses {'ner': 3937.153113023378}\n",
      "Losses {'ner': 4070.612318248488}\n",
      "Losses {'ner': 5621.281921596266}\n",
      "Losses {'ner': 5768.915867597796}\n",
      "Losses {'ner': 6090.569546491839}\n",
      "Losses {'ner': 6313.929545075633}\n",
      "Losses {'ner': 6472.894057662226}\n",
      "Losses {'ner': 6715.791828543879}\n",
      "Losses {'ner': 6919.630269528367}\n",
      "Losses {'ner': 7130.192166090943}\n",
      "Losses {'ner': 7252.817343623377}\n",
      "Losses {'ner': 7408.812942297198}\n",
      "Losses {'ner': 7508.019369513728}\n",
      "Losses {'ner': 7694.127650455572}\n",
      "Losses {'ner': 7907.449442462064}\n",
      "Losses {'ner': 8013.035325185396}\n",
      "Losses {'ner': 8297.812928930856}\n",
      "Losses {'ner': 8475.684547773562}\n",
      "Losses {'ner': 8749.8847769415}\n",
      "Losses {'ner': 9077.137852898799}\n",
      "Losses {'ner': 9147.028478614055}\n",
      "Losses {'ner': 9712.592410079204}\n",
      "Losses {'ner': 9885.864944926463}\n",
      "Losses {'ner': 10034.153531960212}\n",
      "Losses {'ner': 10336.78685133811}\n",
      "Losses {'ner': 10520.551552734338}\n",
      "Losses {'ner': 10709.444456866942}\n",
      "Losses {'ner': 10905.61575232353}\n",
      "Losses {'ner': 10938.156922739465}\n",
      "Losses {'ner': 438.9698886871338}\n",
      "Losses {'ner': 702.8761007785797}\n",
      "Losses {'ner': 985.2764605283737}\n",
      "Losses {'ner': 1271.7062230110168}\n",
      "Losses {'ner': 1321.2762789307162}\n",
      "Losses {'ner': 1513.4694596109912}\n",
      "Losses {'ner': 1631.6766702858731}\n",
      "Losses {'ner': 1800.9197233943269}\n",
      "Losses {'ner': 1839.7310683841351}\n",
      "Losses {'ner': 2038.583952438319}\n",
      "Losses {'ner': 2126.13111682632}\n",
      "Losses {'ner': 2270.0091076681856}\n",
      "Losses {'ner': 2370.068458918715}\n",
      "Losses {'ner': 2604.908241275931}\n",
      "Losses {'ner': 2900.570910219336}\n",
      "Losses {'ner': 3222.2194476167206}\n",
      "Losses {'ner': 3302.5693132320885}\n",
      "Losses {'ner': 3601.8740829864983}\n",
      "Losses {'ner': 3781.2529657960404}\n",
      "Losses {'ner': 3973.4278587659355}\n",
      "Losses {'ner': 4146.202266093111}\n",
      "Losses {'ner': 4241.291779931402}\n",
      "Losses {'ner': 4341.801765557146}\n",
      "Losses {'ner': 4488.449386384105}\n",
      "Losses {'ner': 4667.494574244833}\n",
      "Losses {'ner': 4780.382179762935}\n",
      "Losses {'ner': 4862.414288040018}\n",
      "Losses {'ner': 5130.936028476572}\n",
      "Losses {'ner': 5670.852306362009}\n",
      "Losses {'ner': 5954.098921235418}\n",
      "Losses {'ner': 6120.5843294223305}\n",
      "Losses {'ner': 6312.343975361204}\n",
      "Losses {'ner': 6412.51517223916}\n",
      "Losses {'ner': 6535.873170491075}\n",
      "Losses {'ner': 6654.106156203663}\n",
      "Losses {'ner': 6755.8033551310655}\n",
      "Losses {'ner': 7262.85459700576}\n",
      "Losses {'ner': 7435.219870242989}\n",
      "Losses {'ner': 7716.103664610302}\n",
      "Losses {'ner': 7873.060822400963}\n",
      "Losses {'ner': 7998.041523564374}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 8077.739962925902}\n",
      "Losses {'ner': 8122.018875683076}\n",
      "Losses {'ner': 8321.667310083634}\n",
      "Losses {'ner': 9225.092439974076}\n",
      "Losses {'ner': 9494.490276659257}\n",
      "Losses {'ner': 9586.558628036059}\n",
      "Losses {'ner': 9837.123132421053}\n",
      "Losses {'ner': 9930.654087944306}\n",
      "Losses {'ner': 129.26541508734226}\n",
      "Losses {'ner': 214.40478047635406}\n",
      "Losses {'ner': 269.54634621646255}\n",
      "Losses {'ner': 500.77259208168834}\n",
      "Losses {'ner': 661.2954846462235}\n",
      "Losses {'ner': 718.4055888867006}\n",
      "Losses {'ner': 769.9333646288142}\n",
      "Losses {'ner': 1045.1681394567713}\n",
      "Losses {'ner': 1183.6280086776242}\n",
      "Losses {'ner': 1215.6449912637472}\n",
      "Losses {'ner': 1964.75409732759}\n",
      "Losses {'ner': 2045.4950434453785}\n",
      "Losses {'ner': 2178.9220493920147}\n",
      "Losses {'ner': 2293.566395390779}\n",
      "Losses {'ner': 2443.1004560627043}\n",
      "Losses {'ner': 2537.33314171806}\n",
      "Losses {'ner': 2631.663867284544}\n",
      "Losses {'ner': 2996.5021584527567}\n",
      "Losses {'ner': 3295.8497031228617}\n",
      "Losses {'ner': 3541.291219760664}\n",
      "Losses {'ner': 3616.288329434581}\n",
      "Losses {'ner': 3705.921912563499}\n",
      "Losses {'ner': 3808.139455807861}\n",
      "Losses {'ner': 4285.548683179077}\n",
      "Losses {'ner': 4330.653981037372}\n",
      "Losses {'ner': 4472.000452510947}\n",
      "Losses {'ner': 4920.101712219352}\n",
      "Losses {'ner': 5113.332770518893}\n",
      "Losses {'ner': 5334.516467265719}\n",
      "Losses {'ner': 5529.345547966594}\n",
      "Losses {'ner': 5662.633239082927}\n",
      "Losses {'ner': 5771.032814793223}\n",
      "Losses {'ner': 5865.668002933198}\n",
      "Losses {'ner': 6040.5687926709}\n",
      "Losses {'ner': 6150.421015503052}\n",
      "Losses {'ner': 6269.038835414853}\n",
      "Losses {'ner': 6440.531055563297}\n",
      "Losses {'ner': 6676.12644445261}\n",
      "Losses {'ner': 6885.2116864111085}\n",
      "Losses {'ner': 6986.051659383978}\n",
      "Losses {'ner': 7052.11953518277}\n",
      "Losses {'ner': 7106.712884647008}\n",
      "Losses {'ner': 7514.181020003911}\n",
      "Losses {'ner': 7580.737428722139}\n",
      "Losses {'ner': 7728.263828918971}\n",
      "Losses {'ner': 7827.553909257687}\n",
      "Losses {'ner': 7957.58083867345}\n",
      "Losses {'ner': 8066.918305047489}\n",
      "Losses {'ner': 8229.051214345433}\n",
      "Losses {'ner': 716.8468151092529}\n",
      "Losses {'ner': 767.3353577710222}\n",
      "Losses {'ner': 1223.8969026661944}\n",
      "Losses {'ner': 1346.2913436822128}\n",
      "Losses {'ner': 1555.1999113492202}\n",
      "Losses {'ner': 1627.6107685256284}\n",
      "Losses {'ner': 1724.579044996528}\n",
      "Losses {'ner': 1870.3616176235955}\n",
      "Losses {'ner': 1932.3761332321446}\n",
      "Losses {'ner': 2026.5249237555545}\n",
      "Losses {'ner': 2127.6640098735224}\n",
      "Losses {'ner': 2272.1398535787594}\n",
      "Losses {'ner': 2416.1774295389187}\n",
      "Losses {'ner': 2858.531810623361}\n",
      "Losses {'ner': 2925.1056060462724}\n",
      "Losses {'ner': 3139.8114560514223}\n",
      "Losses {'ner': 3264.403825592948}\n",
      "Losses {'ner': 3307.6165307105985}\n",
      "Losses {'ner': 3418.144163021585}\n",
      "Losses {'ner': 3510.896204408491}\n",
      "Losses {'ner': 3612.295301851118}\n",
      "Losses {'ner': 3682.7616042590234}\n",
      "Losses {'ner': 3728.5981941857863}\n",
      "Losses {'ner': 3781.563192207508}\n",
      "Losses {'ner': 3857.913472075157}\n",
      "Losses {'ner': 3928.5333245947513}\n",
      "Losses {'ner': 3999.692337273762}\n",
      "Losses {'ner': 4166.66194318156}\n",
      "Losses {'ner': 4300.189471944377}\n",
      "Losses {'ner': 4441.1727060518715}\n",
      "Losses {'ner': 4669.887504144714}\n",
      "Losses {'ner': 4760.3253622149605}\n",
      "Losses {'ner': 4907.450761554439}\n",
      "Losses {'ner': 5069.304008124072}\n",
      "Losses {'ner': 5125.630387389709}\n",
      "Losses {'ner': 5186.687424653817}\n",
      "Losses {'ner': 5269.551681751062}\n",
      "Losses {'ner': 5647.6206376493465}\n",
      "Losses {'ner': 5725.535237012107}\n",
      "Losses {'ner': 5877.308056178179}\n",
      "Losses {'ner': 6166.157491507616}\n",
      "Losses {'ner': 6270.401075440135}\n",
      "Losses {'ner': 6346.166897619751}\n",
      "Losses {'ner': 6424.488707567241}\n",
      "Losses {'ner': 6510.855695093658}\n",
      "Losses {'ner': 6577.853001217034}\n",
      "Losses {'ner': 6646.005761235163}\n",
      "Losses {'ner': 6838.534715502665}\n",
      "Losses {'ner': 6855.735233099447}\n",
      "Losses {'ner': 87.96114444732666}\n",
      "Losses {'ner': 167.80138805205934}\n",
      "Losses {'ner': 264.41364362067543}\n",
      "Losses {'ner': 313.74310945603065}\n",
      "Losses {'ner': 817.1853015336674}\n",
      "Losses {'ner': 916.9636146638077}\n",
      "Losses {'ner': 998.2173730942886}\n",
      "Losses {'ner': 1246.204092285363}\n",
      "Losses {'ner': 1347.0997361855116}\n",
      "Losses {'ner': 2225.9986467079725}\n",
      "Losses {'ner': 2303.2272324699443}\n",
      "Losses {'ner': 2425.192920244066}\n",
      "Losses {'ner': 2536.1386846664827}\n",
      "Losses {'ner': 2653.258761220379}\n",
      "Losses {'ner': 2771.2197637788486}\n",
      "Losses {'ner': 2858.3485356492456}\n",
      "Losses {'ner': 2899.0161833155435}\n",
      "Losses {'ner': 3137.7771543848794}\n",
      "Losses {'ner': 3258.971128075151}\n",
      "Losses {'ner': 3322.803517422639}\n",
      "Losses {'ner': 3391.869184485753}\n",
      "Losses {'ner': 3443.920976447058}\n",
      "Losses {'ner': 3582.569817199954}\n",
      "Losses {'ner': 3681.1840909566963}\n",
      "Losses {'ner': 3777.9599307026947}\n",
      "Losses {'ner': 3852.958614796051}\n",
      "Losses {'ner': 3997.603723913082}\n",
      "Losses {'ner': 4200.274112194427}\n",
      "Losses {'ner': 4395.888236850151}\n",
      "Losses {'ner': 4464.818169356906}\n",
      "Losses {'ner': 4576.14751607331}\n",
      "Losses {'ner': 4827.467029632651}\n",
      "Losses {'ner': 4979.808569283807}\n",
      "Losses {'ner': 5071.416396470391}\n",
      "Losses {'ner': 5284.9701338723535}\n",
      "Losses {'ner': 5369.5648511961335}\n",
      "Losses {'ner': 5408.938804775127}\n",
      "Losses {'ner': 5515.593179100775}\n",
      "Losses {'ner': 5571.720013552927}\n",
      "Losses {'ner': 5595.19173593435}\n",
      "Losses {'ner': 5615.940394207719}\n",
      "Losses {'ner': 5923.62606839824}\n",
      "Losses {'ner': 5969.426924421336}\n",
      "Losses {'ner': 6032.659311174299}\n",
      "Losses {'ner': 6119.223406567122}\n",
      "Losses {'ner': 6205.102004012442}\n",
      "Losses {'ner': 6295.350736419088}\n",
      "Losses {'ner': 6397.070957355318}\n",
      "Losses {'ner': 6432.8333485215735}\n",
      "Losses {'ner': 29.645920293871313}\n",
      "Losses {'ner': 64.81509357085451}\n",
      "Losses {'ner': 133.41518640285358}\n",
      "Losses {'ner': 210.05668220343068}\n",
      "Losses {'ner': 305.0849401843734}\n",
      "Losses {'ner': 380.26760954456404}\n",
      "Losses {'ner': 511.62162842648104}\n",
      "Losses {'ner': 571.5474386960268}\n",
      "Losses {'ner': 607.3515880526975}\n",
      "Losses {'ner': 671.0058242911473}\n",
      "Losses {'ner': 730.0655087060295}\n",
      "Losses {'ner': 992.8547266549431}\n",
      "Losses {'ner': 1073.8560494123958}\n",
      "Losses {'ner': 1140.8752730344422}\n",
      "Losses {'ner': 1161.1608902261833}\n",
      "Losses {'ner': 1195.6541259744445}\n",
      "Losses {'ner': 1307.7181781837025}\n",
      "Losses {'ner': 1434.5974339404383}\n",
      "Losses {'ner': 1826.5575325646678}\n",
      "Losses {'ner': 1873.4953806597368}\n",
      "Losses {'ner': 2065.2054679292814}\n",
      "Losses {'ner': 2158.909802091457}\n",
      "Losses {'ner': 3064.8693720224874}\n",
      "Losses {'ner': 3158.214799801968}\n",
      "Losses {'ner': 3266.045380103551}\n",
      "Losses {'ner': 3373.9168451951446}\n",
      "Losses {'ner': 3546.648539297432}\n",
      "Losses {'ner': 3673.650617711395}\n",
      "Losses {'ner': 3740.852020584196}\n",
      "Losses {'ner': 3850.6727607195826}\n",
      "Losses {'ner': 4003.715054506585}\n",
      "Losses {'ner': 4132.593948716447}\n",
      "Losses {'ner': 4252.33137034826}\n",
      "Losses {'ner': 4356.753531458005}\n",
      "Losses {'ner': 4487.890130045042}\n",
      "Losses {'ner': 4604.287289487347}\n",
      "Losses {'ner': 4657.252895100657}\n",
      "Losses {'ner': 4724.964642788433}\n",
      "Losses {'ner': 4853.827730055116}\n",
      "Losses {'ner': 5230.969007368349}\n",
      "Losses {'ner': 5332.579438190125}\n",
      "Losses {'ner': 5434.787432291694}\n",
      "Losses {'ner': 5584.163146454059}\n",
      "Losses {'ner': 5610.728006466907}\n",
      "Losses {'ner': 5676.797688926486}\n",
      "Losses {'ner': 5808.610186966984}\n",
      "Losses {'ner': 5928.327516894704}\n",
      "Losses {'ner': 6011.610403012401}\n",
      "Losses {'ner': 6214.564203239894}\n",
      "Losses {'ner': 102.13642929540947}\n",
      "Losses {'ner': 199.0219366112724}\n",
      "Losses {'ner': 306.217301026918}\n",
      "Losses {'ner': 440.57016845885664}\n",
      "Losses {'ner': 546.3649549121037}\n",
      "Losses {'ner': 687.3056855136529}\n",
      "Losses {'ner': 803.7922592097893}\n",
      "Losses {'ner': 843.447840559762}\n",
      "Losses {'ner': 943.6687637302093}\n",
      "Losses {'ner': 993.2941156201996}\n",
      "Losses {'ner': 1120.4548859321512}\n",
      "Losses {'ner': 1294.0939866029657}\n",
      "Losses {'ner': 1410.7590659582056}\n",
      "Losses {'ner': 1521.7264375560917}\n",
      "Losses {'ner': 1581.3246733490378}\n",
      "Losses {'ner': 2397.3027273956686}\n",
      "Losses {'ner': 2462.544510187581}\n",
      "Losses {'ner': 2525.122209491208}\n",
      "Losses {'ner': 2593.885905848816}\n",
      "Losses {'ner': 2686.591719597578}\n",
      "Losses {'ner': 2761.4249756857753}\n",
      "Losses {'ner': 2820.1781604215503}\n",
      "Losses {'ner': 3025.2387502118945}\n",
      "Losses {'ner': 3094.3616914376616}\n",
      "Losses {'ner': 3141.895344589837}\n",
      "Losses {'ner': 3167.4781214119866}\n",
      "Losses {'ner': 3318.317713272758}\n",
      "Losses {'ner': 3403.9157385313883}\n",
      "Losses {'ner': 3738.8996883118525}\n",
      "Losses {'ner': 3820.596803002991}\n",
      "Losses {'ner': 3914.3194815302268}\n",
      "Losses {'ner': 3992.034272992052}\n",
      "Losses {'ner': 4041.1813519233838}\n",
      "Losses {'ner': 4217.904114239849}\n",
      "Losses {'ner': 4321.222740524448}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 4401.486725571565}\n",
      "Losses {'ner': 4431.891744773835}\n",
      "Losses {'ner': 4484.419576154352}\n",
      "Losses {'ner': 4513.476686221984}\n",
      "Losses {'ner': 4611.649115422246}\n",
      "Losses {'ner': 4623.826384892847}\n",
      "Losses {'ner': 4689.910790447306}\n",
      "Losses {'ner': 4783.257966775607}\n",
      "Losses {'ner': 4873.943890171286}\n",
      "Losses {'ner': 4895.665591694051}\n",
      "Losses {'ner': 5290.876419521504}\n",
      "Losses {'ner': 5397.815369453849}\n",
      "Losses {'ner': 5453.379230570616}\n",
      "Losses {'ner': 5496.700405281605}\n",
      "Losses {'ner': 64.75462181027979}\n",
      "Losses {'ner': 149.54699601512402}\n",
      "Losses {'ner': 240.02370393788442}\n",
      "Losses {'ner': 288.30226641000627}\n",
      "Losses {'ner': 376.27327372172294}\n",
      "Losses {'ner': 571.2228331718725}\n",
      "Losses {'ner': 583.9804660779555}\n",
      "Losses {'ner': 599.508841201583}\n",
      "Losses {'ner': 691.7210893816446}\n",
      "Losses {'ner': 953.1781209892724}\n",
      "Losses {'ner': 1024.9567183641848}\n",
      "Losses {'ner': 1058.7183942398187}\n",
      "Losses {'ner': 1130.7075618406889}\n",
      "Losses {'ner': 1287.1159884533045}\n",
      "Losses {'ner': 1401.0420628389475}\n",
      "Losses {'ner': 1465.0035454532263}\n",
      "Losses {'ner': 1535.4013269115167}\n",
      "Losses {'ner': 1650.1775075271653}\n",
      "Losses {'ner': 1689.2572857141422}\n",
      "Losses {'ner': 1757.292366057627}\n",
      "Losses {'ner': 1820.757912263267}\n",
      "Losses {'ner': 2070.955128177993}\n",
      "Losses {'ner': 2093.2754417711913}\n",
      "Losses {'ner': 2164.040527716097}\n",
      "Losses {'ner': 2289.948787942347}\n",
      "Losses {'ner': 2365.6341617834114}\n",
      "Losses {'ner': 2418.5614468921267}\n",
      "Losses {'ner': 2450.305585841619}\n",
      "Losses {'ner': 2480.1401770137018}\n",
      "Losses {'ner': 2494.4014812664827}\n",
      "Losses {'ner': 2535.8112617050065}\n",
      "Losses {'ner': 2623.5047364876373}\n",
      "Losses {'ner': 2711.860542242299}\n",
      "Losses {'ner': 2743.8565769430966}\n",
      "Losses {'ner': 2781.427872034979}\n",
      "Losses {'ner': 2865.8950545371295}\n",
      "Losses {'ner': 2932.8687343497545}\n",
      "Losses {'ner': 2943.610952319646}\n",
      "Losses {'ner': 3037.1358830203058}\n",
      "Losses {'ner': 3656.613979982281}\n",
      "Losses {'ner': 3720.3922857512475}\n",
      "Losses {'ner': 3773.3600330865697}\n",
      "Losses {'ner': 3832.4124885183514}\n",
      "Losses {'ner': 3885.2805313897074}\n",
      "Losses {'ner': 3994.870265779154}\n",
      "Losses {'ner': 4083.4862003597186}\n",
      "Losses {'ner': 4134.060658079641}\n",
      "Losses {'ner': 4153.981741401232}\n",
      "Losses {'ner': 4168.836517615575}\n",
      "Losses {'ner': 40.68045282457024}\n",
      "Losses {'ner': 114.51171405613422}\n",
      "Losses {'ner': 148.02290146052837}\n",
      "Losses {'ner': 231.33705759048462}\n",
      "Losses {'ner': 361.02646935684606}\n",
      "Losses {'ner': 462.3331368486397}\n",
      "Losses {'ner': 498.51485436363146}\n",
      "Losses {'ner': 569.8255110601895}\n",
      "Losses {'ner': 674.6381808291189}\n",
      "Losses {'ner': 687.3127089472837}\n",
      "Losses {'ner': 1058.2551343771047}\n",
      "Losses {'ner': 1853.6718032690114}\n",
      "Losses {'ner': 1930.9009746941156}\n",
      "Losses {'ner': 2011.7686714408337}\n",
      "Losses {'ner': 2145.094363736862}\n",
      "Losses {'ner': 2385.3318027136265}\n",
      "Losses {'ner': 2461.621952435409}\n",
      "Losses {'ner': 2558.1799862053595}\n",
      "Losses {'ner': 2642.033267356397}\n",
      "Losses {'ner': 2696.155971623899}\n",
      "Losses {'ner': 2811.6484897918417}\n",
      "Losses {'ner': 2927.2711532003595}\n",
      "Losses {'ner': 2952.666365934623}\n",
      "Losses {'ner': 3113.1200150382647}\n",
      "Losses {'ner': 3203.0822773441614}\n",
      "Losses {'ner': 3364.6265753373445}\n",
      "Losses {'ner': 3386.028374943271}\n",
      "Losses {'ner': 3448.321613102773}\n",
      "Losses {'ner': 3615.7613183852227}\n",
      "Losses {'ner': 3689.5277744490595}\n",
      "Losses {'ner': 3736.3342248775007}\n",
      "Losses {'ner': 3763.6094808908238}\n",
      "Losses {'ner': 3831.1957504580787}\n",
      "Losses {'ner': 3881.1649326476327}\n",
      "Losses {'ner': 3924.755303325044}\n",
      "Losses {'ner': 4010.592669090169}\n",
      "Losses {'ner': 4144.554321823554}\n",
      "Losses {'ner': 4263.004868922668}\n",
      "Losses {'ner': 4533.120415745216}\n",
      "Losses {'ner': 4591.610343268054}\n",
      "Losses {'ner': 4651.9264530929795}\n",
      "Losses {'ner': 4683.437227344053}\n",
      "Losses {'ner': 4725.433840012789}\n",
      "Losses {'ner': 4833.3785148110765}\n",
      "Losses {'ner': 4876.590155920625}\n",
      "Losses {'ner': 4965.171892962098}\n",
      "Losses {'ner': 5035.958255006146}\n",
      "Losses {'ner': 5059.879265646596}\n",
      "Losses {'ner': 5117.571898763786}\n",
      "Losses {'ner': 95.25937628000975}\n",
      "Losses {'ner': 133.24785345389682}\n",
      "Losses {'ner': 213.10851274958986}\n",
      "Losses {'ner': 300.67417739859957}\n",
      "Losses {'ner': 344.33376077345747}\n",
      "Losses {'ner': 379.6527665027388}\n",
      "Losses {'ner': 455.10415203245066}\n",
      "Losses {'ner': 501.42634237026505}\n",
      "Losses {'ner': 546.6318221228212}\n",
      "Losses {'ner': 584.9228473951589}\n",
      "Losses {'ner': 613.60436053374}\n",
      "Losses {'ner': 895.9443904886502}\n",
      "Losses {'ner': 966.963925450902}\n",
      "Losses {'ner': 1042.6018606981743}\n",
      "Losses {'ner': 1086.1323029658306}\n",
      "Losses {'ner': 1233.9782950541485}\n",
      "Losses {'ner': 1368.329106621306}\n",
      "Losses {'ner': 1447.9988192225355}\n",
      "Losses {'ner': 1501.6164535545759}\n",
      "Losses {'ner': 1542.2577244416825}\n",
      "Losses {'ner': 1550.0067796030562}\n",
      "Losses {'ner': 1710.3537255445044}\n",
      "Losses {'ner': 1735.9163779987502}\n",
      "Losses {'ner': 1826.8015450018938}\n",
      "Losses {'ner': 1858.6547801414054}\n",
      "Losses {'ner': 2034.8382192983772}\n",
      "Losses {'ner': 2133.1780011601295}\n",
      "Losses {'ner': 2167.0706261698397}\n",
      "Losses {'ner': 2328.840061143437}\n",
      "Losses {'ner': 2409.8724518581766}\n",
      "Losses {'ner': 2524.4127363949556}\n",
      "Losses {'ner': 2673.7273346423644}\n",
      "Losses {'ner': 2977.312342667534}\n",
      "Losses {'ner': 3030.7485772427644}\n",
      "Losses {'ner': 3081.912903437438}\n",
      "Losses {'ner': 3143.9772895873066}\n",
      "Losses {'ner': 3202.006902196492}\n",
      "Losses {'ner': 3381.629529410089}\n",
      "Losses {'ner': 3438.6296293559026}\n",
      "Losses {'ner': 3524.0667680884253}\n",
      "Losses {'ner': 3715.8837415958296}\n",
      "Losses {'ner': 3824.2269830490004}\n",
      "Losses {'ner': 3874.1077628853272}\n",
      "Losses {'ner': 4002.6170516806196}\n",
      "Losses {'ner': 4060.3252925184097}\n",
      "Losses {'ner': 4576.835415771278}\n",
      "Losses {'ner': 4669.328118620488}\n",
      "Losses {'ner': 4687.169801300439}\n",
      "Losses {'ner': 4692.760837049842}\n",
      "Losses {'ner': 158.4368817806244}\n",
      "Losses {'ner': 170.13019433012232}\n",
      "Losses {'ner': 226.73483419325203}\n",
      "Losses {'ner': 352.5106855025515}\n",
      "Losses {'ner': 382.28861270006746}\n",
      "Losses {'ner': 528.5415360135958}\n",
      "Losses {'ner': 683.1015392942354}\n",
      "Losses {'ner': 806.7142882393673}\n",
      "Losses {'ner': 885.4727659826167}\n",
      "Losses {'ner': 1178.5332410936244}\n",
      "Losses {'ner': 1340.232453525532}\n",
      "Losses {'ner': 1443.329904735554}\n",
      "Losses {'ner': 1543.6010016729124}\n",
      "Losses {'ner': 1597.8421261343174}\n",
      "Losses {'ner': 1682.9685835368}\n",
      "Losses {'ner': 1722.8303560863715}\n",
      "Losses {'ner': 2655.899762595771}\n",
      "Losses {'ner': 2734.774196866143}\n",
      "Losses {'ner': 2771.609039945237}\n",
      "Losses {'ner': 2811.4801184918615}\n",
      "Losses {'ner': 2864.81288687879}\n",
      "Losses {'ner': 2910.301102116646}\n",
      "Losses {'ner': 2983.057957075478}\n",
      "Losses {'ner': 3132.7470634206547}\n",
      "Losses {'ner': 3197.5447575654252}\n",
      "Losses {'ner': 3224.3943717572256}\n",
      "Losses {'ner': 3281.6251752990647}\n",
      "Losses {'ner': 3454.037694716768}\n",
      "Losses {'ner': 3505.631607702875}\n",
      "Losses {'ner': 3561.8825439085776}\n",
      "Losses {'ner': 3607.6138882023806}\n",
      "Losses {'ner': 3679.2475229484553}\n",
      "Losses {'ner': 3716.4821477775986}\n",
      "Losses {'ner': 3759.1241641374363}\n",
      "Losses {'ner': 3785.896765997313}\n",
      "Losses {'ner': 3793.6849975576915}\n",
      "Losses {'ner': 3876.3572628489055}\n",
      "Losses {'ner': 4026.545266508154}\n",
      "Losses {'ner': 4042.9621781437017}\n",
      "Losses {'ner': 4066.694881991745}\n",
      "Losses {'ner': 4137.013127576822}\n",
      "Losses {'ner': 4195.544162815233}\n",
      "Losses {'ner': 4237.503482797911}\n",
      "Losses {'ner': 4260.522816908342}\n",
      "Losses {'ner': 4329.519077578356}\n",
      "Losses {'ner': 4360.320372508635}\n",
      "Losses {'ner': 4436.568972796929}\n",
      "Losses {'ner': 4460.798370538076}\n",
      "Losses {'ner': 4472.446030336861}\n",
      "Losses {'ner': 108.45962211489677}\n",
      "Losses {'ner': 176.36509174481034}\n",
      "Losses {'ner': 212.87795502261724}\n",
      "Losses {'ner': 324.01104671077337}\n",
      "Losses {'ner': 332.3359933857573}\n",
      "Losses {'ner': 444.683559751953}\n",
      "Losses {'ner': 480.6394051303796}\n",
      "Losses {'ner': 493.8357831806061}\n",
      "Losses {'ner': 701.7255374759552}\n",
      "Losses {'ner': 720.0565780106117}\n",
      "Losses {'ner': 821.4591022500463}\n",
      "Losses {'ner': 849.9943871175565}\n",
      "Losses {'ner': 877.889528485357}\n",
      "Losses {'ner': 935.103265996433}\n",
      "Losses {'ner': 962.6535283320045}\n",
      "Losses {'ner': 976.195992878922}\n",
      "Losses {'ner': 1043.8190953799567}\n",
      "Losses {'ner': 1109.4702849628447}\n",
      "Losses {'ner': 1126.6559810617982}\n",
      "Losses {'ner': 1241.4667687581896}\n",
      "Losses {'ner': 1296.3617505680813}\n",
      "Losses {'ner': 1372.0471213784112}\n",
      "Losses {'ner': 1397.199319280502}\n",
      "Losses {'ner': 1465.1591145319908}\n",
      "Losses {'ner': 1485.85008960688}\n",
      "Losses {'ner': 1585.5080499174583}\n",
      "Losses {'ner': 1617.5631728692024}\n",
      "Losses {'ner': 1664.4353089107244}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 1734.4096857251643}\n",
      "Losses {'ner': 1766.8048464060485}\n",
      "Losses {'ner': 1783.0288767372913}\n",
      "Losses {'ner': 1835.3079670142106}\n",
      "Losses {'ner': 1853.14058333281}\n",
      "Losses {'ner': 1992.3915126884312}\n",
      "Losses {'ner': 2090.757616918483}\n",
      "Losses {'ner': 2118.445992279281}\n",
      "Losses {'ner': 2190.4703407361594}\n",
      "Losses {'ner': 2302.2450715973464}\n",
      "Losses {'ner': 2630.9858264401046}\n",
      "Losses {'ner': 2643.5923727218833}\n",
      "Losses {'ner': 2682.628000949866}\n",
      "Losses {'ner': 2741.531925225114}\n",
      "Losses {'ner': 2855.2218458889474}\n",
      "Losses {'ner': 2891.4872801615347}\n",
      "Losses {'ner': 2914.492428602134}\n",
      "Losses {'ner': 3112.1918845786204}\n",
      "Losses {'ner': 3192.5710935531606}\n",
      "Losses {'ner': 3219.574226815668}\n",
      "Losses {'ner': 3871.8125357222234}\n",
      "Losses {'ner': 58.995794117450714}\n",
      "Losses {'ner': 197.02937650680542}\n",
      "Losses {'ner': 277.6856497526169}\n",
      "Losses {'ner': 352.7914265394211}\n",
      "Losses {'ner': 579.572402998805}\n",
      "Losses {'ner': 635.4611562635255}\n",
      "Losses {'ner': 695.2846913333487}\n",
      "Losses {'ner': 736.2817981462431}\n",
      "Losses {'ner': 870.2331126858917}\n",
      "Losses {'ner': 912.4118057948508}\n",
      "Losses {'ner': 963.4772543557192}\n",
      "Losses {'ner': 981.7083734124171}\n",
      "Losses {'ner': 1164.7363996598142}\n",
      "Losses {'ner': 1170.07398278644}\n",
      "Losses {'ner': 1352.350268911623}\n",
      "Losses {'ner': 1432.174039494299}\n",
      "Losses {'ner': 1476.4560113866555}\n",
      "Losses {'ner': 1649.4145642538297}\n",
      "Losses {'ner': 1733.89374345734}\n",
      "Losses {'ner': 1876.6675114683549}\n",
      "Losses {'ner': 1952.2376454729329}\n",
      "Losses {'ner': 2043.5446708459149}\n",
      "Losses {'ner': 3329.741261269499}\n",
      "Losses {'ner': 3379.9377121325324}\n",
      "Losses {'ner': 3398.8904535111014}\n",
      "Losses {'ner': 3498.0780322085575}\n",
      "Losses {'ner': 3519.9656873549775}\n",
      "Losses {'ner': 3542.041499527122}\n",
      "Losses {'ner': 3555.3232031715543}\n",
      "Losses {'ner': 3566.5478914293435}\n",
      "Losses {'ner': 3632.242747015038}\n",
      "Losses {'ner': 3676.176888724769}\n",
      "Losses {'ner': 3824.7327007259973}\n",
      "Losses {'ner': 3908.3496175203272}\n",
      "Losses {'ner': 3958.49748084599}\n",
      "Losses {'ner': 4359.970197654309}\n",
      "Losses {'ner': 4470.829340434613}\n",
      "Losses {'ner': 4509.493561344783}\n",
      "Losses {'ner': 4545.890645308982}\n",
      "Losses {'ner': 4569.249944924008}\n",
      "Losses {'ner': 4614.984840239844}\n",
      "Losses {'ner': 4700.797802060357}\n",
      "Losses {'ner': 4744.693491641878}\n",
      "Losses {'ner': 4789.631879378556}\n",
      "Losses {'ner': 4812.646177335157}\n",
      "Losses {'ner': 4840.28994498819}\n",
      "Losses {'ner': 4916.851083104828}\n",
      "Losses {'ner': 4983.105812223026}\n",
      "Losses {'ner': 5063.886979491779}\n",
      "Losses {'ner': 74.87663438834716}\n",
      "Losses {'ner': 114.56348725466523}\n",
      "Losses {'ner': 130.28273739407086}\n",
      "Losses {'ner': 151.00622051763276}\n",
      "Losses {'ner': 213.10870569799954}\n",
      "Losses {'ner': 243.7399434693616}\n",
      "Losses {'ner': 281.0971844926935}\n",
      "Losses {'ner': 310.0652702138286}\n",
      "Losses {'ner': 394.90477916081363}\n",
      "Losses {'ner': 475.4856321461957}\n",
      "Losses {'ner': 558.5414815148797}\n",
      "Losses {'ner': 575.3166814269607}\n",
      "Losses {'ner': 602.6288086464738}\n",
      "Losses {'ner': 697.8485781392192}\n",
      "Losses {'ner': 895.7022852292394}\n",
      "Losses {'ner': 1013.1179952519124}\n",
      "Losses {'ner': 1090.9668241636937}\n",
      "Losses {'ner': 1155.24715562259}\n",
      "Losses {'ner': 1227.0622053565567}\n",
      "Losses {'ner': 1266.8655953453963}\n",
      "Losses {'ner': 1316.2260701223386}\n",
      "Losses {'ner': 1418.0302986963761}\n",
      "Losses {'ner': 1450.5894336993915}\n",
      "Losses {'ner': 1469.4072775150453}\n",
      "Losses {'ner': 1501.3957073896927}\n",
      "Losses {'ner': 1528.2124764944929}\n",
      "Losses {'ner': 1654.6661130994653}\n",
      "Losses {'ner': 1667.7078944037048}\n",
      "Losses {'ner': 1685.30769856389}\n",
      "Losses {'ner': 1845.94285597022}\n",
      "Losses {'ner': 2165.695871317045}\n",
      "Losses {'ner': 2231.796124668078}\n",
      "Losses {'ner': 2265.4130090933604}\n",
      "Losses {'ner': 2298.983030879156}\n",
      "Losses {'ner': 2303.744533968783}\n",
      "Losses {'ner': 2411.1572501302426}\n",
      "Losses {'ner': 2413.085584004685}\n",
      "Losses {'ner': 2471.99427415819}\n",
      "Losses {'ner': 2491.4060957642932}\n",
      "Losses {'ner': 2545.6587839289414}\n",
      "Losses {'ner': 2567.3980717777877}\n",
      "Losses {'ner': 3100.9607331871657}\n",
      "Losses {'ner': 3134.653129282843}\n",
      "Losses {'ner': 3169.657386260543}\n",
      "Losses {'ner': 3196.0428222836626}\n",
      "Losses {'ner': 3337.8087103813587}\n",
      "Losses {'ner': 3361.3749442156686}\n",
      "Losses {'ner': 3381.324603937769}\n",
      "Losses {'ner': 3398.9581627552097}\n",
      "Losses {'ner': 706.9411239624023}\n",
      "Losses {'ner': 723.8583943260601}\n",
      "Losses {'ner': 735.7467702090507}\n",
      "Losses {'ner': 790.3353587411111}\n",
      "Losses {'ner': 851.2277857124573}\n",
      "Losses {'ner': 868.8234479305102}\n",
      "Losses {'ner': 1003.1583628532244}\n",
      "Losses {'ner': 1069.2698656794382}\n",
      "Losses {'ner': 1087.348654932226}\n",
      "Losses {'ner': 1130.4358739553295}\n",
      "Losses {'ner': 1172.9800958496794}\n",
      "Losses {'ner': 1190.094898614408}\n",
      "Losses {'ner': 1197.638755638794}\n",
      "Losses {'ner': 1487.800842185215}\n",
      "Losses {'ner': 1520.114438694612}\n",
      "Losses {'ner': 1622.7310918985763}\n",
      "Losses {'ner': 1675.2945205761948}\n",
      "Losses {'ner': 1708.4640922329286}\n",
      "Losses {'ner': 1717.1538615869954}\n",
      "Losses {'ner': 1767.029811026588}\n",
      "Losses {'ner': 1931.005663754478}\n",
      "Losses {'ner': 1952.0549223116263}\n",
      "Losses {'ner': 1981.2661330318674}\n",
      "Losses {'ner': 2063.931468523167}\n",
      "Losses {'ner': 2091.175744309499}\n",
      "Losses {'ner': 2119.884019862338}\n",
      "Losses {'ner': 2157.862190066249}\n",
      "Losses {'ner': 2290.911640084692}\n",
      "Losses {'ner': 2298.9837857101606}\n",
      "Losses {'ner': 2317.339441470432}\n",
      "Losses {'ner': 2453.88231074028}\n",
      "Losses {'ner': 2506.2094076127773}\n",
      "Losses {'ner': 2547.5604652074194}\n",
      "Losses {'ner': 2817.7456983235693}\n",
      "Losses {'ner': 2826.285085312708}\n",
      "Losses {'ner': 2984.825032691157}\n",
      "Losses {'ner': 3017.2213173192927}\n",
      "Losses {'ner': 3045.928733468149}\n",
      "Losses {'ner': 3093.501927189622}\n",
      "Losses {'ner': 3136.2995134443977}\n",
      "Losses {'ner': 3194.279824723583}\n",
      "Losses {'ner': 3203.5229962492945}\n",
      "Losses {'ner': 3302.299440684414}\n",
      "Losses {'ner': 3400.419014165795}\n",
      "Losses {'ner': 3515.4324517647387}\n",
      "Losses {'ner': 3524.675021668582}\n",
      "Losses {'ner': 3560.319380988984}\n",
      "Losses {'ner': 3658.0957250107663}\n",
      "Losses {'ner': 3658.6483033540385}\n",
      "Losses {'ner': 89.72722466502455}\n",
      "Losses {'ner': 152.21011326860753}\n",
      "Losses {'ner': 168.32538431699504}\n",
      "Losses {'ner': 293.3445621114515}\n",
      "Losses {'ner': 374.2876981701993}\n",
      "Losses {'ner': 472.8583683874749}\n",
      "Losses {'ner': 477.6677392865822}\n",
      "Losses {'ner': 482.7871879153099}\n",
      "Losses {'ner': 530.4766264410719}\n",
      "Losses {'ner': 641.1560239942773}\n",
      "Losses {'ner': 676.3703400331578}\n",
      "Losses {'ner': 688.5762542567354}\n",
      "Losses {'ner': 745.9825333386798}\n",
      "Losses {'ner': 796.7514408856769}\n",
      "Losses {'ner': 877.1494149074097}\n",
      "Losses {'ner': 1174.1304378613968}\n",
      "Losses {'ner': 1220.7773357752849}\n",
      "Losses {'ner': 1321.4480962317575}\n",
      "Losses {'ner': 1347.3572292297285}\n",
      "Losses {'ner': 1420.8783708416995}\n",
      "Losses {'ner': 1448.6445407528336}\n",
      "Losses {'ner': 1455.7190041358808}\n",
      "Losses {'ner': 1475.8624640301095}\n",
      "Losses {'ner': 1545.5805952174815}\n",
      "Losses {'ner': 1631.9722865720505}\n",
      "Losses {'ner': 1744.0321290061802}\n",
      "Losses {'ner': 1757.3262914469924}\n",
      "Losses {'ner': 1840.7745101111468}\n",
      "Losses {'ner': 2097.560863863164}\n",
      "Losses {'ner': 2107.0600292382114}\n",
      "Losses {'ner': 2149.0303032144257}\n",
      "Losses {'ner': 2155.840733025816}\n",
      "Losses {'ner': 2261.848058555868}\n",
      "Losses {'ner': 2448.202993725088}\n",
      "Losses {'ner': 2458.6987096433404}\n",
      "Losses {'ner': 2566.0519786392215}\n",
      "Losses {'ner': 2592.6783050120684}\n",
      "Losses {'ner': 2632.4984076920773}\n",
      "Losses {'ner': 2705.316636093321}\n",
      "Losses {'ner': 2717.3744360661476}\n",
      "Losses {'ner': 2845.1486926084726}\n",
      "Losses {'ner': 2883.315645320934}\n",
      "Losses {'ner': 2898.8744455702363}\n",
      "Losses {'ner': 2920.261007946752}\n",
      "Losses {'ner': 2974.7476147234665}\n",
      "Losses {'ner': 2995.740916849649}\n",
      "Losses {'ner': 3035.398983199684}\n",
      "Losses {'ner': 3069.1530665201826}\n",
      "Losses {'ner': 3109.332965929596}\n",
      "Losses {'ner': 90.74492425657809}\n",
      "Losses {'ner': 137.08299476228422}\n",
      "Losses {'ner': 156.50542077695718}\n",
      "Losses {'ner': 202.02800023829332}\n",
      "Losses {'ner': 224.34461677301442}\n",
      "Losses {'ner': 238.72815214510774}\n",
      "Losses {'ner': 301.3639084111783}\n",
      "Losses {'ner': 301.89896304350987}\n",
      "Losses {'ner': 305.5776102258096}\n",
      "Losses {'ner': 677.1149704171548}\n",
      "Losses {'ner': 721.6935148632474}\n",
      "Losses {'ner': 765.654649364631}\n",
      "Losses {'ner': 773.4939374936075}\n",
      "Losses {'ner': 779.8824572658195}\n",
      "Losses {'ner': 815.8486177206069}\n",
      "Losses {'ner': 823.778257384352}\n",
      "Losses {'ner': 868.5514927726849}\n",
      "Losses {'ner': 906.4606313348427}\n",
      "Losses {'ner': 918.0504109117742}\n",
      "Losses {'ner': 928.1878335204005}\n",
      "Losses {'ner': 962.6401421463147}\n",
      "Losses {'ner': 982.918024703677}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 1030.8421912180406}\n",
      "Losses {'ner': 1061.3399774628838}\n",
      "Losses {'ner': 1108.744993583407}\n",
      "Losses {'ner': 1144.5274259979983}\n",
      "Losses {'ner': 1211.2018122757931}\n",
      "Losses {'ner': 1267.410672349963}\n",
      "Losses {'ner': 1305.1628047382605}\n",
      "Losses {'ner': 1360.2906173491997}\n",
      "Losses {'ner': 1402.3988162657392}\n",
      "Losses {'ner': 1789.867910780586}\n",
      "Losses {'ner': 1833.313757625982}\n",
      "Losses {'ner': 2053.792288956806}\n",
      "Losses {'ner': 2090.9015203338263}\n",
      "Losses {'ner': 2138.7576638531086}\n",
      "Losses {'ner': 2197.8041049648223}\n",
      "Losses {'ner': 2264.5481497306523}\n",
      "Losses {'ner': 2265.518696327018}\n",
      "Losses {'ner': 2287.696293342259}\n",
      "Losses {'ner': 2372.4176305953833}\n",
      "Losses {'ner': 2434.2258311987343}\n",
      "Losses {'ner': 2501.0859709114256}\n",
      "Losses {'ner': 2549.392973816716}\n",
      "Losses {'ner': 2634.524625206129}\n",
      "Losses {'ner': 2667.425382282425}\n",
      "Losses {'ner': 2746.428381483842}\n",
      "Losses {'ner': 2770.4109791021765}\n",
      "Losses {'ner': 2774.0192255181464}\n",
      "Losses {'ner': 71.50711771845818}\n",
      "Losses {'ner': 232.57062728703022}\n",
      "Losses {'ner': 278.12496626004577}\n",
      "Losses {'ner': 374.3556358097121}\n",
      "Losses {'ner': 415.2566293021664}\n",
      "Losses {'ner': 643.6252608736977}\n",
      "Losses {'ner': 684.9788247859105}\n",
      "Losses {'ner': 767.0620033657178}\n",
      "Losses {'ner': 794.7486138520762}\n",
      "Losses {'ner': 803.2634751012083}\n",
      "Losses {'ner': 836.6081061617006}\n",
      "Losses {'ner': 891.948080756003}\n",
      "Losses {'ner': 951.9826028231764}\n",
      "Losses {'ner': 991.0604660125391}\n",
      "Losses {'ner': 1111.3070280017273}\n",
      "Losses {'ner': 1131.4016504198953}\n",
      "Losses {'ner': 1198.834345736279}\n",
      "Losses {'ner': 1263.193709846848}\n",
      "Losses {'ner': 1325.7041645611462}\n",
      "Losses {'ner': 1377.5326426183165}\n",
      "Losses {'ner': 1394.7313118410239}\n",
      "Losses {'ner': 1399.9099749542934}\n",
      "Losses {'ner': 1414.469325674107}\n",
      "Losses {'ner': 1431.3007361002878}\n",
      "Losses {'ner': 1434.8688909880789}\n",
      "Losses {'ner': 1458.5186328509794}\n",
      "Losses {'ner': 1540.1721244751448}\n",
      "Losses {'ner': 1685.1176665236912}\n",
      "Losses {'ner': 1733.6580743396394}\n",
      "Losses {'ner': 1751.2054817106314}\n",
      "Losses {'ner': 1758.290117047282}\n",
      "Losses {'ner': 1862.9954422912765}\n",
      "Losses {'ner': 1917.777499315815}\n",
      "Losses {'ner': 2130.873308179455}\n",
      "Losses {'ner': 2178.4046505331266}\n",
      "Losses {'ner': 2213.94682874032}\n",
      "Losses {'ner': 2229.1753721196205}\n",
      "Losses {'ner': 2288.7550374824555}\n",
      "Losses {'ner': 2314.08922788091}\n",
      "Losses {'ner': 2329.6589726827497}\n",
      "Losses {'ner': 2341.6225397207}\n",
      "Losses {'ner': 2382.423906639886}\n",
      "Losses {'ner': 2481.6882874227285}\n",
      "Losses {'ner': 2564.196518261653}\n",
      "Losses {'ner': 2572.4552785767864}\n",
      "Losses {'ner': 2611.2853138451155}\n",
      "Losses {'ner': 2671.240459770457}\n",
      "Losses {'ner': 2689.696428290814}\n",
      "Losses {'ner': 2690.625365399121}\n",
      "Losses {'ner': 2.4462158253818416}\n",
      "Losses {'ner': 44.56447162175846}\n",
      "Losses {'ner': 82.72976688737344}\n",
      "Losses {'ner': 116.16417372854721}\n",
      "Losses {'ner': 143.21507944794666}\n",
      "Losses {'ner': 177.19745896080804}\n",
      "Losses {'ner': 233.74392631719184}\n",
      "Losses {'ner': 247.46689587947276}\n",
      "Losses {'ner': 365.3037707258418}\n",
      "Losses {'ner': 417.5968480614183}\n",
      "Losses {'ner': 417.7393105744237}\n",
      "Losses {'ner': 464.19928250339274}\n",
      "Losses {'ner': 503.50661111430657}\n",
      "Losses {'ner': 506.68714509985386}\n",
      "Losses {'ner': 560.6767165724838}\n",
      "Losses {'ner': 584.092276616832}\n",
      "Losses {'ner': 621.5481777629999}\n",
      "Losses {'ner': 656.2807171653209}\n",
      "Losses {'ner': 661.0080570037886}\n",
      "Losses {'ner': 709.5455491708186}\n",
      "Losses {'ner': 715.1106114799101}\n",
      "Losses {'ner': 840.8393048459608}\n",
      "Losses {'ner': 850.929166120192}\n",
      "Losses {'ner': 882.9050073542809}\n",
      "Losses {'ner': 954.7201581914329}\n",
      "Losses {'ner': 981.9211445716561}\n",
      "Losses {'ner': 998.4066710077083}\n",
      "Losses {'ner': 1019.432836706014}\n",
      "Losses {'ner': 1099.6094337071613}\n",
      "Losses {'ner': 1220.502341815582}\n",
      "Losses {'ner': 1288.7119107780368}\n",
      "Losses {'ner': 1297.2569855015358}\n",
      "Losses {'ner': 1365.0619086783013}\n",
      "Losses {'ner': 1386.1805368318787}\n",
      "Losses {'ner': 1398.8209538310734}\n",
      "Losses {'ner': 1456.4424750884032}\n",
      "Losses {'ner': 1505.4430748489654}\n",
      "Losses {'ner': 1555.523135234133}\n",
      "Losses {'ner': 1569.6789762646627}\n",
      "Losses {'ner': 1643.0208129127245}\n",
      "Losses {'ner': 1650.535392249058}\n",
      "Losses {'ner': 1656.4187417137532}\n",
      "Losses {'ner': 1676.0724460281003}\n",
      "Losses {'ner': 1699.4601821921337}\n",
      "Losses {'ner': 1962.6158529541958}\n",
      "Losses {'ner': 2054.6680382810105}\n",
      "Losses {'ner': 2122.433368349079}\n",
      "Losses {'ner': 2132.051493707297}\n",
      "Losses {'ner': 2477.822008910773}\n",
      "Losses {'ner': 44.48137279599905}\n",
      "Losses {'ner': 89.36214548864518}\n",
      "Losses {'ner': 158.94521669569076}\n",
      "Losses {'ner': 186.70899120616377}\n",
      "Losses {'ner': 271.67732386421994}\n",
      "Losses {'ner': 405.3214948041423}\n",
      "Losses {'ner': 471.6834114795529}\n",
      "Losses {'ner': 787.1406506305539}\n",
      "Losses {'ner': 832.8563233768546}\n",
      "Losses {'ner': 856.0577296634183}\n",
      "Losses {'ner': 887.1310319733784}\n",
      "Losses {'ner': 1091.7775949669049}\n",
      "Losses {'ner': 1165.2887647357747}\n",
      "Losses {'ner': 1224.3356251279802}\n",
      "Losses {'ner': 1295.766764642296}\n",
      "Losses {'ner': 1324.4046676931648}\n",
      "Losses {'ner': 1402.5800644028702}\n",
      "Losses {'ner': 1524.6161921694645}\n",
      "Losses {'ner': 1582.0699189850045}\n",
      "Losses {'ner': 1603.4961626845386}\n",
      "Losses {'ner': 1873.1769215780284}\n",
      "Losses {'ner': 1925.55198797574}\n",
      "Losses {'ner': 1932.8523740000735}\n",
      "Losses {'ner': 1942.895624071424}\n",
      "Losses {'ner': 1946.667553435874}\n",
      "Losses {'ner': 1994.7712883640572}\n",
      "Losses {'ner': 1996.9505807997368}\n",
      "Losses {'ner': 2017.7450317798823}\n",
      "Losses {'ner': 2099.5882849125364}\n",
      "Losses {'ner': 2104.3641786357807}\n",
      "Losses {'ner': 2140.197945070821}\n",
      "Losses {'ner': 2182.9839959902642}\n",
      "Losses {'ner': 2205.208752450843}\n",
      "Losses {'ner': 2221.959881887177}\n",
      "Losses {'ner': 2224.245389428251}\n",
      "Losses {'ner': 2304.5234455431632}\n",
      "Losses {'ner': 2320.486786782242}\n",
      "Losses {'ner': 2338.002827484592}\n",
      "Losses {'ner': 2362.0941691875582}\n",
      "Losses {'ner': 2468.5040603347247}\n",
      "Losses {'ner': 2472.598156019669}\n",
      "Losses {'ner': 2591.36055606566}\n",
      "Losses {'ner': 2623.979922029745}\n",
      "Losses {'ner': 2674.3489548001403}\n",
      "Losses {'ner': 2719.4758875501307}\n",
      "Losses {'ner': 2763.6646956520585}\n",
      "Losses {'ner': 2889.4022984521894}\n",
      "Losses {'ner': 2903.449630106457}\n",
      "Losses {'ner': 2953.149702190079}\n",
      "Losses {'ner': 23.42967093695188}\n",
      "Losses {'ner': 47.07157869680486}\n",
      "Losses {'ner': 80.30345987604778}\n",
      "Losses {'ner': 158.84840701503526}\n",
      "Losses {'ner': 171.6188764197923}\n",
      "Losses {'ner': 191.43015713926252}\n",
      "Losses {'ner': 237.2348787685096}\n",
      "Losses {'ner': 287.0041895949453}\n",
      "Losses {'ner': 323.2086969877764}\n",
      "Losses {'ner': 342.837398320733}\n",
      "Losses {'ner': 390.53810042917576}\n",
      "Losses {'ner': 397.0559877289397}\n",
      "Losses {'ner': 404.4799093158854}\n",
      "Losses {'ner': 459.1418825538767}\n",
      "Losses {'ner': 525.0794757783351}\n",
      "Losses {'ner': 546.503741751605}\n",
      "Losses {'ner': 548.1945725048354}\n",
      "Losses {'ner': 676.8416719960442}\n",
      "Losses {'ner': 761.2810899374672}\n",
      "Losses {'ner': 795.0131713321098}\n",
      "Losses {'ner': 1555.4735232760795}\n",
      "Losses {'ner': 1608.7399198582061}\n",
      "Losses {'ner': 1631.8293497666382}\n",
      "Losses {'ner': 1670.1271154268543}\n",
      "Losses {'ner': 1713.5299695113572}\n",
      "Losses {'ner': 1725.6654206540625}\n",
      "Losses {'ner': 1749.7385431170187}\n",
      "Losses {'ner': 1764.821332856147}\n",
      "Losses {'ner': 1777.1096032858425}\n",
      "Losses {'ner': 1838.4061325491004}\n",
      "Losses {'ner': 1876.8464848938695}\n",
      "Losses {'ner': 1878.4262339064483}\n",
      "Losses {'ner': 1898.8607412666026}\n",
      "Losses {'ner': 2044.7275154381934}\n",
      "Losses {'ner': 2078.397902106568}\n",
      "Losses {'ner': 2115.5151924916354}\n",
      "Losses {'ner': 2121.472905902543}\n",
      "Losses {'ner': 2144.375154815034}\n",
      "Losses {'ner': 2145.676527721781}\n",
      "Losses {'ner': 2171.153639168452}\n",
      "Losses {'ner': 2174.823621794344}\n",
      "Losses {'ner': 2203.7565280159424}\n",
      "Losses {'ner': 2205.8919629795723}\n",
      "Losses {'ner': 2226.8004516717206}\n",
      "Losses {'ner': 2333.4915391188274}\n",
      "Losses {'ner': 2377.7602411145504}\n",
      "Losses {'ner': 2422.138961263948}\n",
      "Losses {'ner': 2555.0945908511217}\n",
      "Losses {'ner': 2601.9632534468706}\n",
      "Losses {'ner': 80.24154301732779}\n",
      "Losses {'ner': 89.25025622974499}\n",
      "Losses {'ner': 118.90263946875348}\n",
      "Losses {'ner': 148.73930137380376}\n",
      "Losses {'ner': 152.92902672736273}\n",
      "Losses {'ner': 158.69700594097594}\n",
      "Losses {'ner': 171.41031010997358}\n",
      "Losses {'ner': 197.80009071087807}\n",
      "Losses {'ner': 201.77270725492417}\n",
      "Losses {'ner': 256.6374188874106}\n",
      "Losses {'ner': 279.5440503338541}\n",
      "Losses {'ner': 287.3173499605691}\n",
      "Losses {'ner': 407.9062230372874}\n",
      "Losses {'ner': 463.9245887743382}\n",
      "Losses {'ner': 510.0778541397376}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 524.1117698215603}\n",
      "Losses {'ner': 545.8020323777528}\n",
      "Losses {'ner': 555.5468800754825}\n",
      "Losses {'ner': 562.6229755260356}\n",
      "Losses {'ner': 572.9187376514819}\n",
      "Losses {'ner': 579.4199469954804}\n",
      "Losses {'ner': 609.9247601073332}\n",
      "Losses {'ner': 724.8895360225908}\n",
      "Losses {'ner': 760.9754187459223}\n",
      "Losses {'ner': 786.3792386757307}\n",
      "Losses {'ner': 798.1147057506353}\n",
      "Losses {'ner': 865.1860550287277}\n",
      "Losses {'ner': 868.9861141780864}\n",
      "Losses {'ner': 927.8721973442014}\n",
      "Losses {'ner': 978.081132500666}\n",
      "Losses {'ner': 1052.0114867090313}\n",
      "Losses {'ner': 1060.1591998107622}\n",
      "Losses {'ner': 1084.6759436011205}\n",
      "Losses {'ner': 1124.92580416723}\n",
      "Losses {'ner': 1427.8801586918423}\n",
      "Losses {'ner': 1431.2044792089443}\n",
      "Losses {'ner': 1485.6269306156616}\n",
      "Losses {'ner': 1550.4060557156633}\n",
      "Losses {'ner': 1664.4911132573914}\n",
      "Losses {'ner': 1670.676343975507}\n",
      "Losses {'ner': 1688.258573410951}\n",
      "Losses {'ner': 1706.1652820766378}\n",
      "Losses {'ner': 1739.0876724263128}\n",
      "Losses {'ner': 1819.3494117897992}\n",
      "Losses {'ner': 2071.886957411194}\n",
      "Losses {'ner': 2080.60086570995}\n",
      "Losses {'ner': 2106.298359511775}\n",
      "Losses {'ner': 2147.5996278350995}\n",
      "Losses {'ner': 2197.3397107555365}\n",
      "Losses {'ner': 52.378384024021216}\n",
      "Losses {'ner': 81.66584885353222}\n",
      "Losses {'ner': 107.343241845374}\n",
      "Losses {'ner': 115.79082545443089}\n",
      "Losses {'ner': 178.11020894526155}\n",
      "Losses {'ner': 230.52166322989797}\n",
      "Losses {'ner': 236.08091889599746}\n",
      "Losses {'ner': 256.91083964191785}\n",
      "Losses {'ner': 347.8704826482426}\n",
      "Losses {'ner': 382.12597710870614}\n",
      "Losses {'ner': 392.3312614583265}\n",
      "Losses {'ner': 418.3992670872103}\n",
      "Losses {'ner': 424.67962611996336}\n",
      "Losses {'ner': 439.61591843692213}\n",
      "Losses {'ner': 448.1601762627138}\n",
      "Losses {'ner': 457.14184129190426}\n",
      "Losses {'ner': 471.81932778053897}\n",
      "Losses {'ner': 510.5203105534588}\n",
      "Losses {'ner': 513.4519300506051}\n",
      "Losses {'ner': 570.2725678266268}\n",
      "Losses {'ner': 588.2731469277767}\n",
      "Losses {'ner': 601.9801132489645}\n",
      "Losses {'ner': 621.8338501922387}\n",
      "Losses {'ner': 623.4753054979399}\n",
      "Losses {'ner': 624.9902978465941}\n",
      "Losses {'ner': 654.3755849698607}\n",
      "Losses {'ner': 679.5643168389613}\n",
      "Losses {'ner': 680.5868722343655}\n",
      "Losses {'ner': 690.3152661363854}\n",
      "Losses {'ner': 698.641432515127}\n",
      "Losses {'ner': 740.3841971778454}\n",
      "Losses {'ner': 786.1104358979644}\n",
      "Losses {'ner': 820.7472509262295}\n",
      "Losses {'ner': 1035.970230486724}\n",
      "Losses {'ner': 1053.1231698483605}\n",
      "Losses {'ner': 1059.7776114090916}\n",
      "Losses {'ner': 1124.7527516957011}\n",
      "Losses {'ner': 1125.1813738559063}\n",
      "Losses {'ner': 1131.15793017028}\n",
      "Losses {'ner': 1153.3605309146}\n",
      "Losses {'ner': 1155.8539383909579}\n",
      "Losses {'ner': 1181.7303567598487}\n",
      "Losses {'ner': 1186.2784695960145}\n",
      "Losses {'ner': 1272.2143098467077}\n",
      "Losses {'ner': 1416.1411470823969}\n",
      "Losses {'ner': 1423.07766840172}\n",
      "Losses {'ner': 1432.6602747410816}\n",
      "Losses {'ner': 1757.1617433995289}\n",
      "Losses {'ner': 1766.2425278189858}\n",
      "Losses {'ner': 20.647671246202663}\n",
      "Losses {'ner': 49.12744940118864}\n",
      "Losses {'ner': 55.420294313837076}\n",
      "Losses {'ner': 90.5662096470187}\n",
      "Losses {'ner': 95.74099013480009}\n",
      "Losses {'ner': 133.00526749985875}\n",
      "Losses {'ner': 139.42823248068453}\n",
      "Losses {'ner': 223.48932957361103}\n",
      "Losses {'ner': 241.8880654925306}\n",
      "Losses {'ner': 256.51899514059187}\n",
      "Losses {'ner': 336.1810491242504}\n",
      "Losses {'ner': 339.757341036885}\n",
      "Losses {'ner': 390.6517843169486}\n",
      "Losses {'ner': 444.82355773759537}\n",
      "Losses {'ner': 601.0563883812492}\n",
      "Losses {'ner': 614.2549716977728}\n",
      "Losses {'ner': 622.5604046257422}\n",
      "Losses {'ner': 639.4965624269307}\n",
      "Losses {'ner': 738.5676937680901}\n",
      "Losses {'ner': 828.6059448602819}\n",
      "Losses {'ner': 846.1913539350271}\n",
      "Losses {'ner': 865.3857674367382}\n",
      "Losses {'ner': 875.1211597867405}\n",
      "Losses {'ner': 952.877568741711}\n",
      "Losses {'ner': 1012.4317231582572}\n",
      "Losses {'ner': 1012.8837715389604}\n",
      "Losses {'ner': 1025.6643037130057}\n",
      "Losses {'ner': 1027.2514357560462}\n",
      "Losses {'ner': 1060.547218343188}\n",
      "Losses {'ner': 1087.918281995098}\n",
      "Losses {'ner': 1100.7695103873152}\n",
      "Losses {'ner': 1134.7966477934856}\n",
      "Losses {'ner': 1140.026632306242}\n",
      "Losses {'ner': 1152.5478869850808}\n",
      "Losses {'ner': 1199.0984280581647}\n",
      "Losses {'ner': 1210.7571705321348}\n",
      "Losses {'ner': 1285.2622141765928}\n",
      "Losses {'ner': 1383.4258037274153}\n",
      "Losses {'ner': 1393.2589306372424}\n",
      "Losses {'ner': 1398.3100668296}\n",
      "Losses {'ner': 1404.8493895563777}\n",
      "Losses {'ner': 1435.175642454579}\n",
      "Losses {'ner': 1477.1553002312328}\n",
      "Losses {'ner': 1506.5325972172911}\n",
      "Losses {'ner': 1511.5329889616744}\n",
      "Losses {'ner': 1720.8085535130278}\n",
      "Losses {'ner': 1740.5742767098175}\n",
      "Losses {'ner': 1747.6754368158338}\n",
      "Losses {'ner': 1749.697316962241}\n",
      "Losses {'ner': 16.42366120528459}\n",
      "Losses {'ner': 27.67241433874733}\n",
      "Losses {'ner': 27.72750338088008}\n",
      "Losses {'ner': 61.18952474477919}\n",
      "Losses {'ner': 119.89043825553017}\n",
      "Losses {'ner': 208.77662817449527}\n",
      "Losses {'ner': 212.41730647189434}\n",
      "Losses {'ner': 247.37832919256653}\n",
      "Losses {'ner': 270.33947968697066}\n",
      "Losses {'ner': 387.5607475659799}\n",
      "Losses {'ner': 438.3988324369293}\n",
      "Losses {'ner': 577.9110122363072}\n",
      "Losses {'ner': 659.0620144049626}\n",
      "Losses {'ner': 662.1162361877709}\n",
      "Losses {'ner': 719.6577888729721}\n",
      "Losses {'ner': 829.6848490836769}\n",
      "Losses {'ner': 898.0570407543769}\n",
      "Losses {'ner': 978.132936017259}\n",
      "Losses {'ner': 1008.7537636287948}\n",
      "Losses {'ner': 1025.8741823329678}\n",
      "Losses {'ner': 1038.1375919726183}\n",
      "Losses {'ner': 1125.870390429764}\n",
      "Losses {'ner': 1137.9538166543557}\n",
      "Losses {'ner': 1189.7211232978939}\n",
      "Losses {'ner': 1217.0357893050736}\n",
      "Losses {'ner': 1240.9777313896543}\n",
      "Losses {'ner': 1268.0930277297361}\n",
      "Losses {'ner': 1271.9872050102}\n",
      "Losses {'ner': 1295.1234961553305}\n",
      "Losses {'ner': 1306.130399330013}\n",
      "Losses {'ner': 1420.8263309062054}\n",
      "Losses {'ner': 1439.302791189762}\n",
      "Losses {'ner': 1589.5536271300039}\n",
      "Losses {'ner': 1600.0137333305424}\n",
      "Losses {'ner': 1668.3601918773597}\n",
      "Losses {'ner': 1697.1854257647751}\n",
      "Losses {'ner': 1775.1424733485433}\n",
      "Losses {'ner': 1783.1521773039926}\n",
      "Losses {'ner': 1794.6257296000472}\n",
      "Losses {'ner': 1811.8768678797564}\n",
      "Losses {'ner': 1842.1207119288079}\n",
      "Losses {'ner': 1854.555388377506}\n",
      "Losses {'ner': 1881.348054086316}\n",
      "Losses {'ner': 1887.0889618956348}\n",
      "Losses {'ner': 1895.3366978178015}\n",
      "Losses {'ner': 1907.0720150132179}\n",
      "Losses {'ner': 1938.7469318882427}\n",
      "Losses {'ner': 1962.3430207984852}\n",
      "Losses {'ner': 1967.8142128258107}\n",
      "Losses {'ner': 555.6338093280792}\n",
      "Losses {'ner': 555.8250284324206}\n",
      "Losses {'ner': 586.0617429987508}\n",
      "Losses {'ner': 615.8483362031441}\n",
      "Losses {'ner': 628.4702083012346}\n",
      "Losses {'ner': 660.149051298413}\n",
      "Losses {'ner': 662.1843141428322}\n",
      "Losses {'ner': 676.31148036247}\n",
      "Losses {'ner': 702.1222967865539}\n",
      "Losses {'ner': 712.1952504866418}\n",
      "Losses {'ner': 744.0950168535707}\n",
      "Losses {'ner': 745.266066226213}\n",
      "Losses {'ner': 764.5048590405273}\n",
      "Losses {'ner': 807.8630335657286}\n",
      "Losses {'ner': 832.0234176560549}\n",
      "Losses {'ner': 921.4281495555548}\n",
      "Losses {'ner': 931.0225666216353}\n",
      "Losses {'ner': 945.8364036916533}\n",
      "Losses {'ner': 948.3903455918262}\n",
      "Losses {'ner': 954.0009444929965}\n",
      "Losses {'ner': 1017.290451689747}\n",
      "Losses {'ner': 1048.4732330537008}\n",
      "Losses {'ner': 1111.8880895560214}\n",
      "Losses {'ner': 1120.4063857508227}\n",
      "Losses {'ner': 1133.118406894464}\n",
      "Losses {'ner': 1139.8679721294639}\n",
      "Losses {'ner': 1195.7073841630217}\n",
      "Losses {'ner': 1200.4263624970165}\n",
      "Losses {'ner': 1204.9241974623842}\n",
      "Losses {'ner': 1233.2853106465159}\n",
      "Losses {'ner': 1244.3432526450867}\n",
      "Losses {'ner': 1321.3579315535987}\n",
      "Losses {'ner': 1409.5330233399088}\n",
      "Losses {'ner': 1448.319485075053}\n",
      "Losses {'ner': 1457.2866000335869}\n",
      "Losses {'ner': 1547.0378640692886}\n",
      "Losses {'ner': 1563.0610765109473}\n",
      "Losses {'ner': 1571.262913684785}\n",
      "Losses {'ner': 1587.9413683561975}\n",
      "Losses {'ner': 1633.6107485376665}\n",
      "Losses {'ner': 1860.6509522347146}\n",
      "Losses {'ner': 1871.3258409864707}\n",
      "Losses {'ner': 1924.0154949213816}\n",
      "Losses {'ner': 1929.5377410689603}\n",
      "Losses {'ner': 1983.0440374312225}\n",
      "Losses {'ner': 2007.3741816670868}\n",
      "Losses {'ner': 2033.156407320616}\n",
      "Losses {'ner': 2054.5382173068124}\n",
      "Losses {'ner': 2065.0094568285335}\n"
     ]
    }
   ],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(30):\n",
    "    print(\"iteration:\", iteration)\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(training_data)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(training_data, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        #print(annotations)\n",
    "        nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sai Patha\\nMule ESB Integration Developer - Cisco Systems\\n\\nHyderabad, Telangana - Email me on Indeed: indeed.com/r/Sai-Patha/981ba615ab108e29\\n\\n 6+ years of professional experience in end-to-end designing, developing and implementation\\nof\\nsoftware solutions in the areas of Middleware Integration and J2EE based applications.\\n Expertise in the areas of Core Java, Servlet 2.3, JSP, Web Services, MESB, and OSB.\\n Expertise in PL SQL programming and Oracle Apps (Oracle Order management)\\n Having 2.5+ years of experience in Mule and expert in Mule ESB development (3.7v & 3.8v),\\nMule\\nESB administration and Mule API management (API GW 1.x, 2.x, 3.x) CloudHub.\\n Experience in building Mule ESB & API management platform for organizations\\n Experience in performance tuning, testing, and benchmarking the platform for the\\norganization.\\n Expert in building middleware systems using Message Routing, Content Enrichment, Cache\\nMechanism, Message Filtering, Message Transformation, Message sequencing, Batch message\\nprocessing, Error handling and reconciliation mechanisms.\\n Expertise in designing and implementing multi-tiered application with high performance using\\nJ2EE standards.\\n Good understanding of API management systems - Mulesoft and RAML.\\n Experience in compiling proof of concepts and presenting to customers.\\n Deep knowledge of all phases of software engineering involving analysis, design and\\nimplementation.\\n Hands on experience in load testing and performance testing and setting up the environment.\\n Very strong debugging skills.\\n Expertise in implementing different J2EE design patterns and Java Multi-Threading.\\n Hands on experience in creating Splunk dashboard, App for production proactive monitoring\\nand\\nfor reporting.\\n Good understanding in Web services security.\\n Extensively worked on servers Apache Tomcat, JBoss, Web logic and WebSphere.\\n Familiar with reviewing Functional Requirements and writing Technical Specifications.\\n Extensive Expertise in using Oracle 11i.\\n Broad knowledge of version control systems, build scripts and logging mechanisms.\\n Analysis, design and development of Applications based on J2EE & allied technologies using\\nAgile\\nmethodology.\\n Implementing high-end performance REST services for Middleware using Core Java.\\n Deploying Builds to DEV/TEST/PROD environment using Kintana, Udeploy & URelease tools.\\n Implementation of modules using Core Java APIs, Java collection, XML technologies and\\nintegrating the modules.\\n Responsible for converting the understood business into Technical Specification document.\\n Taking KT sessions from client on Application functionality and discuss with Business Analysts to\\nintegrate new functionalities with existing systems.\\n Utilize Oracle as back-end database and TOAD for querying.\\n Utilize Log4j as logging mechanism and developed wrapper class to configure the logs.\\n Utilize CVS, SVN, and GIT as Version control tool.\\n\\nhttps://www.indeed.com/r/Sai-Patha/981ba615ab108e29?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n Used Maven build scripts to create and deploy the release builds.\\n Prepare the Functional and Technical Design documents.\\n Module implementation and customization based on the Change Requests.\\n Development and support for different releases before and after implementation of launch.\\n Review the fellow developers' code as an exercise of internal code review.\\n Carry out Configuration Management activities for projects.\\n Carry out Weekly Status reporting activities such as MOM updates and health sheet generation.\\n Excellent communication and interpersonal skills. Involved in client interactions for scoping,\\neffort\\nestimates and status reporting.\\n\\nWORK EXPERIENCE\\n\\nMule ESB Integration Developer\\n\\nCisco Systems -  San Jose, CA -\\n\\nApril 2017 to Present\\n\\nProject: Extended Enterprise B2B Transformation\\n\\nResponsibilities\\n Followed agile methodology and Scrum.\\n Involved in application design and participated in technical meetings, Effort estimations,\\nbacklog\\ngrooming, I&A etc.\\n Involved in analyzing, developing, troubleshooting, debugging, and optimizing ESB application.\\n Involved in documenting and presenting designed technical solutions.\\n Extensively used Anypoint studio to develop and design the business process.\\n Implemented complex transformation Logics using MEL\\n Building RESTful Web Services with Anypoint Platform for APIs\\n Involved in data transformation and mapping using data weave\\n Tested the business process in test mode for debugging\\n Build and deployed using Anypoint studio, maven.\\n Participating i n meeting and on-calls\\n Code reviews and independent unit testing for components\\n Manage code release deployment into development, SIT, OAT and production\\n Error handling is properly done in all the business processes\\nTechnologies: Mule Server 3.7 EE, Anypoint studio 5.4, cloud hub, Maven, core java, GIT, RAML,\\nAPIKit, SOAP 01, Postman, Agile, Jenkins.\\n\\nMule Soft Team Lead\\n\\nCisco Systems -  San Jose, CA -\\n\\nJune 2016 to March 2017\\n\\nProject:FSMS\\n\\nResponsibilities:\\n Followed agile methodology and Scrum.\\n\\n\\n\\n Involved in application design and participated in technical meetings, Effort estimations,\\nbacklog\\ngrooming, I&A etc.\\n Gather requirements and planning on integration of oracle data base with cloud applications\\nusing\\nMule ESB.\\n Tightly integrated applications using MULE ESB.\\n Involved in implementing ESB flows, Proxies, logging and exception handling.\\n Extensively used Mule ESB components like File Transport, SMTP Transport, FTP/SFTP\\nTransport, JDBC Connector, JMS and Transaction Manager.\\n Used TOAD for internal data storage and retrieval.\\n Involved in setting up Connection pooling and used JMS for Asynchronous messaging.\\n Setting up Mule ESB for the development environment.\\n Developed application using Mule ESB and deployed the services in dev, test and prod\\nenvironments. And also done with Unit testing using Test Utility.\\n Migrated Mule ESB 3.7.0 apps to Mule ESB 3.8.4\\n Applied OAUTH authentication policy for API proxies\\n Have integrated web services including SOAP as well as REST using Mule ESB.\\n QA, UAT & Production issues investigation and supporting business users.\\n\\nMule Soft Team Lead\\n\\nCisco Systems -  San Jose, CA -\\n\\nAugust 2015 to May 2016\\n\\nProject: Bay Bridge RMA Services\\n\\n Design and implement the Mule ESB platform for Cisco.\\n Design and implement the RESTful WS using RAML to interact with AI system and storing in\\nC3 Database.\\n Implemented the security for the SOAP and REST Web services using OAUTH and Basic\\nAuthentication.\\n Designed and developed the core modules, which pulls service request details from CSOne\\nSystem.\\n Design and developed common modules like Audit Logging, which can be used as a common\\nmodule and shared resources for all the applications.\\n Designed the Exception handling for all the apps on Mule platform.\\n Designed the Domain to share the resource like HTTP, HTTPS & DB connector references.\\n Created flows for basic authentication and caching the token for OAUTH.\\n Have carried out performance testing for the ESB flows for memory leakage and for fine-tuning.\\n Worked with Mule team on some of the issue with performance on DB connector.\\n Interacted with dependent teams (CSONE and PEGA) and came up with the design on the\\nimplementation of the flows and architecture and design of services.\\n Developed required back Java components.\\n Reported and worked on DB connector Connection pool issues to Mulesoft.\\n Reported and worked on MMC deployment issues with Mulesoft.\\nTechnologies: Java 1.8, Oracle11i Web Services, Mule ESB, Mule API Manager, XML, JSON,\\nAnypoint Studio, Maven, GIT, SVN, ESB Servers.\\n\\nTechnology Analyst\\n\\n\\n\\nCisco Systems -  San Jose, CA -\\n\\nDecember 2013 to July 2015\\n\\nProject: OMLSS\\n\\n Understanding of the complete architecture of the system including boundary systems.\\n Understand the client and project requirements by studying the existing documentation and\\nseeking clarifications, if any, to participate efficiently in the Development and Testing phases of\\nthe project.\\n Create program specifications, unit test plans for software programs by studying functional\\nand non-functional requirements, the application architecture document, and converting the\\nassigned\\nfunctionalities into pseudo code/algorithms/test cases.\\n Develop code using knowledge of relevant technology as per design specifications and\\ndocument\\nartifacts such as unit test scripts, etc. independently and support peers in identifying code defects\\nand ensuring that the output is as per the given specifications and SLAs.\\n Perform testing - self and independent (Functional, Integration, System) - as per defined\\nprocesses and guidelines to ensure accurate program output; identify and resolve defects, if any.\\n Work on 'Go Live' activities as per the Implementation plan and manage any issues related to\\nfunctionalities, user interface, performance, etc. that may arise.\\n Respond to the issues assigned, conduct analysis of the issues assigned, identify and evaluate\\ndifferent workarounds/ solution alternatives, implement the most optimal solution, support other\\nteam members on issue resolution in areas of expertise as required, manage stakeholder\\ncommunication and close the issues assigned in order to ensure support availability as per\\nagreed\\nSLAs.\\n Understand application architecture document and seek inputs from the architecture / design\\nteam to understand the overall architecture IN ORDER TO provide deliverables that are in line\\nwith architectural requirements.\\n\\nTechnologies: Java 1.5, Web services, Oracle 11i, XML, Eclipse, HP Quality Center, SVN, Jenkins,\\nuDeploy and uRelease.\\n\\nSr.Software Engineer\\n\\nCisco Systems -  San Jose, CA -\\n\\nJune 2013 to November 2013\\n\\nProject: SPED Integration\\n\\nResponsibilities:\\n Responsible for development of Oracle Interfaces and Mapping data as per requirements of\\nCisco\\nBrazil.\\n Involved in the development of PL/SQL queries to fetch data from the oracle and insertion of\\nData into Synchro Open Interface tables. This is a very critical data reporting as the data is to be\\nreported to the Government of Brazil by Cisco as per the Legal Procedures. He was involved in the\\n\\n\\n\\nDevelopment of Packages, Concurrent Programs and many other Custom functionalities as per\\nthe Requirements.\\n Experience in Cisco Quality Control process and Migration of Code into Different Environments.\\n Implemented the PL/SQL based on the requirements of AP and RI modules.\\n\\nTechnologies: PL/SQL, Oracle Applications (Financials), PVCS, Kintana, Toad.\\n\\nSoftware Engineer\\n\\nCisco Systems -  San Jose, CA -\\n\\nApril 2012 to May 2013\\n\\nProject: IT Creative Solutions (ITCS)\\n\\nResponsibilities:\\n Understand the business process and build interactive online dashboards based on client\\nrequirement.\\n Do the data modelling to hold the current data, to sustain future needs and drilldowns in the\\ndashboards.\\n Use dashboard building tools Xcelsius, Tableau to build interactive dashboards.\\n Develop business layer to perform all the calculations used in dashboard.\\n Do client interaction and communication to get required inputs.\\n Participated in Client Demos and meetings.\\n\\nTechnologies: SQL Server, Tableau, Xcelsius.\\n\\nSoftware Engineer\\n\\nArrow Electronics Inc -\\n\\nAugust 2011 to March 2012\\n\\nProject: Arrow Unity (Sales Work Bench)\\n\\nResponsibilities:\\n Requirements gathering, designing, development and testing.\\n Ownership of the deliverables.\\n Involved in Post Production support for SWB application.\\n Coding and testing for enhancements.\\n Wrote Oracle PL/SQL Stored procedures, triggers, and views for backend database access.\\n UAT Testing Support.\\n\\nTechnologies: Unix, ExtJs, Pl/Sql\\n\\nEDUCATION\\n\\nBachelor of Technology in Technology\\n\\nAmrita School of Engineering\\n\\n2007 to 2011\\n\\n\\n\\nSKILLS\\n\\nORACLE (3 years), JAVA (3 years), SOAP (2 years), Subversion (2 years), SVN (2 years)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\nLanguages Java, Java Script, PL/SQL, SQL SERVER, HTML, XML,\\nXSLT\\nApplication Servers J Boss, Apache Tomcat, Web logic, IBM web sphere\\n\\nDatabases Oracle, SQL SERVER\\n\\nDevelopment Tools MVC, Singleton, Session Facade, DTO, DAO,\\n\\nService Locator\\n\\nSOA Restful Web Service, Soap web service, JAX-RS, XML, JSON, WS\\nSecurity, Mule ESB\\n\\nIDE's/TOOLS Eclipse, Mule Anypoint Studio\\n\\nJava/J2EETechnologies Java, Servlets, JSP, JDBC, EJB, JMS\\n\\nProtocols HTTP, FTP, TCP/IP\\n\\nVersion Control tools CVS, SVN, GIT\\n\\nBuild Tool Ant, Maven\\n\\nBug Tracking Tools HP Quality Center, Rally\\n\\nFrameworks Spring, Hibernate, Struts, Spring MVC, Micro Services, EJB, JMS\\n\\nOperating Systems Windows, UNIX, LINUX\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = training_data[0][0]\n",
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict2 = \"Maxine Curry\\\n",
    "Dayjob.com\\\n",
    "The Big Peg\\\n",
    "120 Vyse Street\\\n",
    "Birmingham B18 6NF\\\n",
    "England\\\n",
    "T: 0044 121 638 0026\\\n",
    "E: info@dayjob.com\\\n",
    "PERSONAL SUMMARY\\\n",
    "Maxine can ensure that IT Infrastructure is secure, reliable, fit for purpose and evolves with a businesses needs. You can rely on her to create flexible, secure and first-class systems which will save you time, money and allow you to grow your business. In the past she has built her own complete IT function from scratch. She enjoys working with her peers to identify and advise on new cutting-edge solutions that can improve their productivity. As a true professional she will ensure that all relevant risks, especially with regards to information infrastructure are documented and managed appropriately. On a personal level she is comfortable making decisions and taking responsibility at a senior level. Right now, she is looking to join a young, proactive, driven and above all fun organisation that has big plans for the future.\\\n",
    "CAREER HISTORY\\\n",
    "IT MANAGER  Start Date  Present\\\n",
    "Employers name  Location\\\n",
    "Responsible for helping the company to remain IT compliant, efficient and profitable during the course of its operations.\\\n",
    "Duties;\\\n",
    "Ensuring that the companys IT systems are readily available for use by staff.\\\n",
    "Making sure key staff are appropriately trained in the usage of all IT products and services in order to effectively carry out their jobs.\\\n",
    "Identifying opportunities to improve efficiencies using technology.\\\n",
    "Designing IT training programs and workshops for staff.\\\n",
    "Leading, motivating and managing a small Infrastructure and Service Desk team.\\\n",
    "Managing the businesses websites and domains.\\\n",
    "Being the point of contact for operational IT matters when senior managers or directors are unavailable.\\\n",
    "Providing colleagues with step-by-step technical help in both verbal and written format.\\\n",
    "In charge of IT budgeting, controlling costs and keeping the department on track financially.\\\n",
    "Maintaining a log and list of all required repairs, upgrades and maintenance.\\\n",
    "JOB TITLE  Start Date  End Date\\\n",
    "Employers name  Location\\\n",
    "KEY SKILLS AND COMPETENCIES\\\n",
    "Professional\\\n",
    "Experience of working with MSPs and around Service Integration.\\\n",
    "Knowledge and understanding of Database, network and communication protocols.\\\n",
    "Successful track record in relationship management with key stakeholders.\\\n",
    "Good ability to inform stakeholders and manage their expectations.\\\n",
    "Relevant project management experience particularly in delivering small and large scale IT projects.\\\n",
    "Personal\\\n",
    "Excellent verbal and written communication and facilitation skills.\\\n",
    "Willing to travel at short notice to sites across the country.\\\n",
    "AREAS OF EXPERTISE\\\n",
    "Goal setting\\\n",
    "IT Management\\\n",
    "Staff motivation\\\n",
    "IT security\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Sai Patha', 'Name'), ('Mule ESB Integration Developer', 'Designation'), ('Cisco Systems', 'Companies worked at'), ('Hyderabad', 'Location'), ('indeed.com/r/Sai-Patha/981ba615ab108e29', 'Email Address'), ('Mule ESB Integration Developer', 'Designation'), ('Cisco Systems', 'Companies worked at'), ('Cisco Systems', 'Companies worked at'), ('Cisco Systems', 'Companies worked at'), ('Cisco Systems', 'Companies worked at'), ('Software Engineer', 'Designation'), ('Cisco Systems', 'Companies worked at'), ('Software Engineer', 'Designation'), ('Cisco Systems', 'Companies worked at'), ('Software Engineer', 'Designation'), ('Arrow Electronics Inc', 'Companies worked at'), ('2011', 'Graduation Year'), ('Bachelor of Technology in Technology', 'Degree'), ('Amrita School of Engineering', 'College Name'), ('2011', 'Graduation Year'), ('ORACLE (3 years), JAVA (3 years), SOAP (2 years), Subversion (2 years), SVN (2 years)', 'Skills'), ('Languages Java, Java Script, PL/SQL, SQL SERVER, HTML, XML,\\n', 'Skills')]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "doc = nlp(to_predict)\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the  model to directory\n",
    "output_dir = Path('/content/')\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)\n",
    "\n",
    "# Load the saved model and predict\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp_updated = spacy.load(output_dir)\n",
    "doc = nlp_updated(\"Fridge can be ordered in FlipKart\" )\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
